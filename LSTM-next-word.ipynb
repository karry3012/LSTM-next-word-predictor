{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4WkOGI0Ut8OO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , LSTM , Flatten , Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\"\"Deep learning is a subset of machine learning inspired by the structure and function of the brain, called artificial neural networks.\n",
        "It involves training models with multiple layers of neurons, hence \"deep\" networks.\n",
        "Neurons in deep learning are mathematical functions that process inputs and pass on results to subsequent layers.\n",
        "Each layer in a deep network learns a higher-level feature, from simple edges in images to complex shapes or objects.\n",
        "Activation functions like ReLU and Sigmoid help introduce non-linearity, enabling networks to solve complex problems.\n",
        "Backpropagation is the process through which deep networks adjust weights based on errors, optimizing performance.\n",
        "Common architectures include Convolutional Neural Networks (CNNs) for image data and Recurrent Neural Networks (RNNs) for sequential data.\n",
        "Deep learning excels in areas requiring high-dimensional data analysis, such as computer vision, speech recognition, and NLP.\n",
        "Training deep networks typically requires large datasets and significant computational power.\n",
        "Overfitting is a common challenge where the model performs well on training data but poorly on new data.\n",
        "Regularization techniques like dropout and weight decay help to mitigate overfitting.\n",
        "Transfer learning allows models trained on one task to be fine-tuned for another, reducing the need for extensive data.\n",
        "Autoencoders are used in deep learning for unsupervised tasks, like dimensionality reduction and anomaly detection.\n",
        "Generative Adversarial Networks (GANs) are a type of deep learning model used to generate new, synthetic data samples.\n",
        "Deep reinforcement learning combines deep learning with reinforcement learning, enabling agents to learn complex tasks.\n",
        "Optimizers like Adam and SGD (Stochastic Gradient Descent) are crucial for effectively training deep models.\n",
        "Deep learning is data-hungry, requiring extensive labeled data to train accurately.\n",
        "The hardware advancements, especially GPUs and TPUs, have been critical for deep learning's progress.\n",
        "Frameworks like TensorFlow, PyTorch, and Keras have made deep learning accessible and manageable.\n",
        "Deep learning continues to evolve, pushing the boundaries in AI applications across industries, from healthcare to entertainment.\n",
        "Sure! Here’s a concise overview of deep learning in lines, each line containing words or fewer:\n",
        "Deep learning is a subset of machine learning that mimics the human brain’s structure and function.\n",
        "It uses artificial neural networks (ANNs) with multiple layers to process data and make predictions or classifications.\n",
        "Deep learning models learn from large datasets, extracting patterns that would be difficult for traditional machine learning.\n",
        "The core idea is to enable computers to automatically improve their performance through exposure to more data.\n",
        "Neural networks consist of input, hidden, and output layers, with each layer representing different levels of abstraction.\n",
        "The input layer receives raw data, which is passed through hidden layers for processing, and the output layer makes predictions.\n",
        "Activation functions, like ReLU and Sigmoid, introduce non-linearity, helping networks to solve complex problems.\n",
        "Backpropagation adjusts weights in the network by minimizing the error between predicted and actual outputs.\n",
        "Gradient descent is used to minimize the loss function by updating model parameters iteratively.\n",
        "Deep learning thrives on big data, where the more data you provide, the better the model’s performance.\n",
        "A Convolutional Neural Network (CNN) is designed for processing image data and identifying spatial hierarchies.\n",
        "CNNs use convolutional layers to detect patterns in images, such as edges, shapes, and textures.\n",
        "Recurrent Neural Networks (RNNs) are suited for sequential data, like time series or natural language processing (NLP).\n",
        "RNNs have loops that allow information to persist across sequences, making them ideal for tasks like speech recognition.\n",
        "Long Short-Term Memory (LSTM) is a type of RNN that solves the vanishing gradient problem in long sequences.\n",
        "LSTMs use memory cells to store information for long durations, overcoming short-term memory limitations of traditional RNNs.\n",
        "Generative Adversarial Networks (GANs) consist of two networks: a generator and a discriminator, used for data generation.\n",
        "GANs are popular for creating synthetic data like images, videos, and even music.\n",
        "Autoencoders are unsupervised neural networks that learn efficient data representations for tasks like dimensionality reduction.\n",
        "Deep Reinforcement Learning combines deep learning with reinforcement learning to train agents to make decisions in complex environments.\n",
        "Overfitting occurs when a model learns the training data too well, including noise, and generalizes poorly to new data.\n",
        "Regularization techniques like dropout and L2 regularization help prevent overfitting by penalizing overly complex models.\n",
        "Dropout randomly disables neurons during training, forcing the network to learn more robust features.\n",
        "Data augmentation artificially increases the size of the dataset by applying random transformations like rotations or flips.\n",
        "Deep learning models often require specialized hardware like GPUs or TPUs to accelerate training.\n",
        "GPUs parallelize computations, allowing deep networks to process large datasets much faster than CPUs.\n",
        "Transfer learning leverages pre-trained models on one task and fine-tunes them for another task, saving time and data.\n",
        "Transfer learning has proven effective for image and text classification tasks, especially with limited data.\n",
        "Deep learning models are data-hungry, requiring massive amounts of labeled data to train effectively.\n",
        "Labeling data can be expensive and time-consuming, especially for specialized tasks like medical image analysis.\n",
        "Optimizers like Adam and Stochastic Gradient Descent (SGD) are used to update weights during training.\n",
        "Adam combines the benefits of momentum and adaptive learning rates, often providing better results than SGD.\n",
        "Hyperparameters like learning rate, batch size, and network architecture must be carefully tuned for optimal performance.\n",
        "Cross-validation helps assess the model’s performance by dividing the data into training and validation sets.\n",
        "Early stopping prevents overfitting by halting training once the model’s performance on the validation set stops improving.\n",
        "Loss functions like Mean Squared Error (MSE) or Cross-Entropy are used to evaluate how well the model predicts.\n",
        "Deep learning has revolutionized areas like computer vision, natural language processing, and speech recognition.\n",
        "Object detection and image segmentation are specific tasks within computer vision that have seen great improvements.\n",
        "In NLP, deep learning models have greatly advanced tasks like machine translation, text generation, and sentiment analysis.\n",
        "Transformers are a type of model architecture that has become the foundation for state-of-the-art NLP models like GPT.\n",
        "The BERT model revolutionized NLP by enabling pre-training on vast corpora of text for a wide range of tasks.\n",
        "GPT-3, a large transformer model, has achieved state-of-the-art results in natural language understanding and generation.\n",
        "Attention mechanisms in deep learning help models focus on important parts of input data, improving performance on sequential tasks.\n",
        "Self-supervised learning uses unlabeled data by predicting parts of data from other parts, helping train models with fewer labels.\n",
        "Reinforcement learning enables agents to learn by interacting with an environment and receiving rewards based on their actions.\n",
        "Deep learning models can be used for anomaly detection in fields like finance, cybersecurity, and healthcare.\n",
        "Training deep learning models requires a significant amount of computational power and resources, especially for large datasets.\n",
        "Batch normalization helps stabilize and speed up training by normalizing activations within each mini-batch.\n",
        "Weight initialization techniques like Xavier or He initialization help start the training process with balanced weights.\n",
        "Hyperparameter optimization techniques like grid search or random search can help find the best set of parameters for training.\n",
        "Deep learning models are typically evaluated using metrics like accuracy, precision, recall, and F1 score.\n",
        "Confusion matrices visualize the performance of classification models, showing true positives, false positives, and other metrics.\n",
        "Hyperparameter tuning is an important step in improving deep learning model performance by experimenting with different configurations.\n",
        "Learning rate schedules adjust the learning rate over time to prevent overfitting and improve convergence.\n",
        "Batch size affects how much data is processed at once during training, influencing both training speed and model performance.\n",
        "Data preprocessing steps like normalization or scaling improve the efficiency and accuracy of deep learning models.\n",
        "Feature extraction involves selecting and transforming raw input data into meaningful features for the model to process.\n",
        "Multi-task learning allows a single model to solve multiple related tasks simultaneously, sharing knowledge between tasks.\n",
        "Ensemble methods combine predictions from multiple models to improve overall performance and reduce errors.\n",
        "Model compression techniques like pruning or quantization reduce the size of deep learning models, making them more efficient.\n",
        "Model interpretability helps understand how deep learning models make predictions, increasing trust and transparency in their decisions.\n",
        "Explainable AI (XAI) aims to make complex models like deep learning more understandable to humans.\n",
        "Federated learning enables training models across decentralized data sources while maintaining data privacy and security.\n",
        "Transfer learning makes it easier to build deep learning models for specific tasks without requiring massive datasets.\n",
        "Recurrent Neural Networks (RNNs) are ideal for modeling time-dependent data, like stock prices or weather forecasting.\n",
        "Image classification involves assigning labels to images based on their content, a core task in computer vision.\n",
        "Speech-to-text and text-to-speech applications use deep learning to convert spoken language into text and vice versa.\n",
        "Voice assistants like Siri and Alexa rely on deep learning for natural language understanding and response generation.\n",
        "Neural machine translation uses deep learning to translate text from one language to another, improving over traditional methods.\n",
        "Speech recognition models convert human speech into text, enabling applications like voice typing and real-time translation.\n",
        "Style transfer applies the artistic style of one image to another, using deep learning for creative applications.\n",
        "Neural networks are inspired by biological neurons but are designed mathematically to handle various types of data.\n",
        "Neurons in deep learning models are connected to each other, forming a network where each connection has a weight.\n",
        "The training process involves adjusting weights to minimize the difference between predicted and actual outputs.\n",
        "Deep learning can be used for time series forecasting, predicting future values based on past data.\n",
        "Reinforcement learning is used in robotics to teach machines to perform tasks like object manipulation and navigation.\n",
        "Anomaly detection using deep learning can identify unusual patterns in data, such as fraudulent activity or system failures.\n",
        "Image captioning generates descriptive text for images, combining computer vision and natural language processing techniques.\n",
        "Semantic segmentation labels each pixel in an image, useful for tasks like medical image analysis and autonomous driving.\n",
        "Object recognition identifies and classifies objects within an image, such as faces or vehicles.\n",
        "Deep learning models are used in robotic vision, enabling robots to interpret their surroundings and make decisions.\n",
        "Generative models like GANs create new data by learning the distribution of existing data.\n",
        "Deep learning algorithms are particularly well-suited for pattern recognition tasks in diverse fields like biology and marketing.\n",
        "Deep learning models are computationally expensive, often requiring large amounts of memory and processing power.\n",
        "Ethics in AI is an important consideration when deploying deep learning systems in sensitive areas like healthcare and law enforcement.\n",
        "Bias in AI models can lead to unfair or discriminatory outcomes, necessitating\n",
        "careful attention during training and deployment.\n",
        "AI safety focuses on ensuring that deep learning models act in alignment with human values and priorities.\n",
        "AI governance involves establishing policies and guidelines for the responsible development and deployment of deep learning systems.\n",
        "Automated machine learning (AutoML) frameworks simplify deep learning model creation by automating tasks like feature engineering and hyperparameter tuning.\n",
        "Deep learning models have enabled major advancements in healthcare, such as automated diagnostics and drug discovery.\n",
        "Medical imaging uses deep learning to analyze X-rays, MRIs, and other images for detecting diseases like cancer.\n",
        "Reinforcement learning agents are used to train self-driving cars to navigate complex environments autonomously.\n",
        "Deep learning is integral to the development of intelligent assistants, which improve productivity and user experience.\n",
        "Deep learning is continuously evolving, with researchers exploring new architectures and techniques to improve performance.\n",
        "Neural network pruning helps reduce model size by removing unnecessary weights, maintaining performance with fewer parameters.\n",
        "Quantization converts floating-point numbers into lower precision formats, reducing memory usage and computational costs.\n",
        "Deep learning models are often evaluated on test datasets to assess their generalization ability on unseen data.\n",
        "Overfitting prevention techniques like dropout and early stopping help maintain a balance between model complexity and generalization.\n",
        "Zero-shot learning allows models to make predictions on tasks they haven't seen during training by leveraging prior knowledge.\n",
        "The future of deep learning holds immense potential for solving complex problems in fields like climate science and space exploration.\n",
        "Sure! Here is a concise list of lines about CNN layers and RNN models, with each line being less than or equal to words:\n",
        "### CNN Layers:\n",
        "Convolutional Layer (Conv Layer) applies a filter to input data to create feature maps.\n",
        "The filter slides over input data, detecting features like edges, textures, or patterns.\n",
        "Stride defines the step size of the filter as it moves across the input image.\n",
        "Padding adds extra pixels around the input image to maintain the output dimensions.\n",
        "Activation function like ReLU introduces non-linearity to the output of the convolution.\n",
        "Pooling layers reduce spatial dimensions of feature maps, typically using MaxPooling or AveragePooling.\n",
        "MaxPooling selects the maximum value in each sub-region of the feature map.\n",
        "AveragePooling takes the average value in each sub-region of the feature map.\n",
        "Fully Connected Layer (FC) connects every neuron in the previous layer to the next layer.\n",
        "Batch Normalization normalizes inputs to improve training speed and stability.\n",
        "Dropout randomly disables neurons during training to reduce overfitting.\n",
        "Global Average Pooling reduces each feature map to a single value by averaging the entire map.\n",
        "Convolutional Neural Networks (CNNs) excel at image-related tasks like classification and detection.\n",
        "Depthwise Separable Convolution reduces computational cost by applying convolution in two stages.\n",
        "Dilated Convolution uses spaced-out filters to capture larger context without increasing the filter size.\n",
        "1x1 Convolutions combine information across feature maps without spatial reduction.\n",
        "Transposed Convolutions (Deconvolutions) upsample the input feature maps.\n",
        "Separable Convolutions apply a separate convolution over the width and height of an image.\n",
        "ResNet (Residual Networks) use skip connections to bypass layers, allowing for deeper networks.\n",
        "Inception Networks use multiple filter sizes at once to capture features at different scales.\n",
        "AlexNet is one of the first CNN models to use deep architecture for image classification.\n",
        "VGGNet uses smaller filter sizes (3x3) stacked in deeper layers for better feature extraction.\n",
        "LeNet is an early CNN model designed for handwritten digit recognition.\n",
        "SqueezeNet reduces the number of parameters while maintaining high performance in image classification.\n",
        "MobileNet is optimized for mobile devices with fewer parameters and operations.\n",
        "DenseNet uses dense connections between layers to improve feature reuse and gradients flow.\n",
        "Xception is based on depthwise separable convolutions, improving efficiency and performance.\n",
        "U-Net is a popular architecture for semantic segmentation with a symmetric encoder-decoder structure.\n",
        "Faster R-CNN adds Region Proposal Networks (RPN) for object detection.\n",
        "YOLO (You Only Look Once) is a real-time object detection model that predicts bounding boxes directly.\n",
        "SSD (Single Shot MultiBox Detector) detects objects in images with multiple scale features.\n",
        "FPN (Feature Pyramid Network) enhances multi-scale detection using a top-down architecture.\n",
        "RNN layers are used to process sequential data by maintaining hidden states across timesteps.\n",
        "Recurrent Layer in CNNs captures temporal dependencies in time series data.\n",
        "Convolutional RNN (CRNN) combines CNNs for feature extraction and RNNs for sequence processing.\n",
        "Global Pooling summarizes feature maps into a single value for classification tasks.\n",
        "1D Convolution is used for sequence data like time series or text.\n",
        "3D Convolution extends convolution to three dimensions, commonly used for video data.\n",
        "Spatial Attention Layer helps focus on important regions in feature maps.\n",
        "Temporal Attention Layer focuses on important time steps in sequential data.\n",
        "ResNeXt introduces a split-transform-merge strategy for better performance with fewer parameters.\n",
        "Neural Style Transfer uses CNNs to transfer artistic styles onto images.\n",
        "Spatial Pyramid Pooling handles images of varying sizes without resizing them.\n",
        "RNN-based encoder-decoder is used in machine translation for sequence-to-sequence tasks.\n",
        "Attention Mechanism improves model focus on specific parts of input sequences, enhancing learning.\n",
        "Dilated Convolution increases the receptive field of the network without increasing the filter size.\n",
        "Transfer Learning uses pre-trained CNN models to improve performance on new tasks with fewer data.\n",
        "Feature Extraction with CNNs captures hierarchical features from low-level to high-level.\n",
        "ResNet-50 has layers and is a lightweight architecture compared to deeper ResNet variants.\n",
        "AlexNet introduced the use of GPUs in training deep networks, improving speed.\n",
        "Activation Maps represent the output from a convolutional layer after applying activation functions.\n",
        "CNN with LSTM combines spatial and sequential modeling for tasks like image captioning.\n",
        "Batch Normalization Layer standardizes inputs to each layer to maintain stable training.\n",
        "Dropout Layer randomly sets a fraction of input units to zero to prevent overfitting.\n",
        "Pooling Layers help to downsample the feature maps, reducing computational cost.\n",
        "Fully Connected Layer typically comes at the end of a CNN model for decision-making.\n",
        "CNN in Object Detection identifies objects within an image by predicting bounding boxes.\n",
        "RNN with LSTM remembers long-term dependencies in sequences like text or speech.\n",
        "Word Embedding Layer converts words into vector representations for RNN-based language models.\n",
        "Bidirectional RNN processes sequences in both forward and backward directions for better context.\n",
        "CNN for Image Classification identifies objects or scenes in an image.\n",
        "CNNs for Semantic Segmentation predict class labels for each pixel in an image.\n",
        "CNN for Object Detection finds objects within images and classifies them.\n",
        "Semantic Segmentation classifies each pixel of an image into a category.\n",
        "CNNs for Face Recognition detect and identify faces in images using deep features.\n",
        "Instance Segmentation combines object detection and semantic segmentation tasks.\n",
        "Region of Interest Pooling helps CNNs focus on relevant parts of an image.\n",
        "CNN for Video Classification processes video frames to classify actions or objects.\n",
        "CNN for Anomaly Detection detects abnormal patterns in data, such as in security.\n",
        "RNN in Language Modeling predicts the next word in a sentence based on previous words.\n",
        "GRU (Gated Recurrent Unit) is a type of RNN with simplified gating mechanisms compared to LSTMs.\n",
        "LSTM (Long Short-Term Memory) improves RNNs by capturing long-term dependencies and mitigating vanishing gradients.\n",
        "Bidirectional LSTM enhances LSTM by processing sequences in both directions, capturing better context.\n",
        "Vanishing Gradient Problem limits RNNs from learning long-term dependencies effectively.\n",
        "Gated Recurrent Unit (GRU) is faster and simpler than LSTM with similar performance.\n",
        "Deep RNN models learn more complex patterns in data by stacking RNN layers.\n",
        "Attention-Based RNN uses attention mechanisms to focus on important parts of sequences.\n",
        "RNN for Speech Recognition converts audio signals into text by processing temporal information.\n",
        "RNN for Text Generation generates sequences of text based on patterns learned from data.\n",
        "Encoder-Decoder RNNs convert an input sequence to an output sequence of varying lengths.\n",
        "Hierarchical Attention Networks (HAN) use multiple attention layers to understand document structure.\n",
        "RNN for Sentiment Analysis processes text data to determine the sentiment of sentences.\n",
        "LSTM Networks handle sequences by learning long-term dependencies in time-series data.\n",
        "Recurrent Neural Networks excel in tasks where temporal or sequential information is essential.\n",
        "RNN for Machine Translation translates text between languages by modeling sentence structures.\n",
        "RNN for Video Captioning generates textual descriptions for video content by processing frames sequentially.\n",
        "Long Short-Term Memory (LSTM) prevents the vanishing gradient problem by maintaining memory over time.\n",
        "RNNs for Time-Series Forecasting predict future values based on historical time-series data.\n",
        "Sequence-to-Sequence (Seq2Seq) Models are used for tasks like translation and summarization.\n",
        "Attention Mechanism in RNNs helps models focus on significant parts of input sequences.\n",
        "GRU vs LSTM: GRUs are faster and simpler; LSTMs are more robust with complex dependencies.\n",
        "RNN for Video Analysis processes temporal frames to recognize actions or objects in a video.\n",
        "RNN for Named Entity Recognition identifies specific entities (names, dates) in a sequence.\n",
        "Bidirectional RNN enhances RNN by processing sequences from both forward and reverse directions.\n",
        "Stacked RNNs involve stacking multiple RNN layers to capture more complex patterns.\n",
        "Attention in Seq2Seq Models improves performance by focusing on relevant parts of the input sequence.\n",
        "Temporal Convolutional Networks (TCN) replace RNNs with convolutions for sequential data tasks.\n",
        "Residual Networks (ResNet) use skip connections to allow for deeper networks in CNNs.\n",
        "GRU vs LSTM: GRUs use fewer parameters\n",
        "than LSTMs while maintaining performance.\n",
        "RNNs for Language Translation translate sentences from one language to another using sequential learning.\n",
        "Machine learning (ML) is a field of AI that focuses on algorithms that allow computers to learn from data.\n",
        "It enables systems to recognize patterns, make decisions, and improve over time without being explicitly programmed.\n",
        "ML involves supervised, unsupervised, and reinforcement learning techniques to handle various types of data and tasks.\n",
        "Supervised learning uses labeled data to train models that predict outcomes for unseen data.\n",
        "Unsupervised learning identifies hidden patterns in data without labels, often used for clustering and association tasks.\n",
        "Reinforcement learning trains agents through trial and error, optimizing actions to maximize long-term rewards in dynamic environments.\n",
        "Deep learning, a subset of ML, uses neural networks with multiple layers to solve complex problems like image recognition.\n",
        "ML algorithms require large amounts of data to learn effectively, making data quality and quantity critical.\n",
        "Feature engineering plays a crucial role in determining which aspects of data are most valuable for predictive models.\n",
        "Overfitting occurs when a model learns the training data too well, losing its ability to generalize to new data.\n",
        "Underfitting happens when a model is too simple and fails to capture the underlying patterns in the data.\n",
        "Cross-validation helps assess a model's performance by splitting data into multiple subsets for training and testing.\n",
        "Common ML algorithms include linear regression, decision trees, random forests, support vector machines, and neural networks.\n",
        "ML has applications across industries, including healthcare, finance, entertainment, and autonomous systems.\n",
        "Natural language processing (NLP) is a branch of ML focused on enabling machines to understand human language.\n",
        "ML-based recommendation systems power platforms like Netflix and Amazon, suggesting content based on user behavior.\n",
        "Computer vision, another key application, uses ML to enable machines to interpret and analyze visual data.\n",
        "Ethical concerns in ML include data privacy, algorithmic bias, and the potential for misuse in surveillance systems.\n",
        "Interpretability and explainability of ML models are crucial to ensure transparency and trust in AI systems.\n",
        "ML models can be deployed through cloud platforms, allowing scalability and access to powerful computational resources.\n",
        "Transfer learning allows models trained on one task to be fine-tuned for similar tasks with less data.\n",
        "Hyperparameter tuning optimizes ML models by adjusting parameters to improve accuracy and efficiency during training.\n",
        "Reinforcement learning has been successful in training agents for gaming, robotics, and self-driving cars.\n",
        "ML is revolutionizing industries, driving advancements in automation, predictive analytics, and intelligent systems.\n",
        "Data preprocessing steps, like normalization and handling missing values, are vital for effective model training.\n",
        "Bias in training data can lead to biased ML outcomes, potentially reinforcing stereotypes or discriminatory practices.\n",
        "ML can help in anomaly detection, identifying unusual patterns in data such as fraud or network intrusions.\n",
        "Gradient descent is a widely used optimization technique for minimizing errors and improving ML model accuracy.\n",
        "Ensemble methods, like boosting and bagging, combine multiple models to enhance performance and reduce overfitting.\n",
        "Clustering algorithms like K-means group similar data points, useful for market segmentation and pattern discovery.\n",
        "Time series forecasting uses ML to predict future data points based on historical trends and patterns.\n",
        "Artificial neural networks are inspired by the human brain, with layers of nodes that mimic neurons.\n",
        "ML models require continuous monitoring to ensure they remain accurate and relevant as new data arrives.\n",
        "The accuracy of an ML model depends on its ability to minimize errors and generalize well to new data.\n",
        "Semi-supervised learning combines both labeled and unlabeled data to improve model performance with fewer labels.\n",
        "Anomaly detection can spot outliers, helping detect fraud, cyberattacks, or equipment malfunctions.\n",
        "The development of robust ML models requires iterative testing, refinement, and performance evaluation.\n",
        "ML models can be prone to adversarial attacks, where small changes to input data mislead the model.\n",
        "Feature selection reduces the dimensionality of the data, focusing on the most relevant attributes for modeling.\n",
        "AutoML tools automate the process of model selection and optimization, making ML accessible to non-experts.\n",
        "Hyperparameter optimization techniques like grid search and random search help fine-tune ML model parameters.\n",
        "Active learning uses human feedback to improve the learning process when labeled data is scarce.\n",
        "Generative models, like GANs, are used to create new data, such as images or music, that resemble real data.\n",
        "Federated learning allows models to be trained on distributed devices, ensuring data privacy and security.\n",
        "ML is transforming the healthcare industry, enabling predictive diagnostics, personalized treatment plans, and drug discovery.\n",
        "Ethical AI requires that ML models be fair, transparent, and accountable in their decision-making processes.\n",
        "ML-powered chatbots use NLP to engage in conversations, providing customer support and automating tasks.\n",
        "Large language models like GPT use massive datasets and deep learning to generate human-like text responses.\n",
        "ML algorithms continually evolve, leveraging research advancements and computational power to solve more complex problems.\n",
        "As ML matures, it promises to drive innovation across sectors, enhancing efficiency, creativity, and decision-making capabilities.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "PYv3PgQRzRTV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "QA72ARubzkiB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "N4AjHKTY0OdL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oMWPyFUh0TGe",
        "outputId": "ebc80f5f-0292-4562-bdee-89572ea0f6c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1,\n",
              " 'to': 2,\n",
              " 'the': 3,\n",
              " 'learning': 4,\n",
              " 'data': 5,\n",
              " 'for': 6,\n",
              " 'in': 7,\n",
              " 'of': 8,\n",
              " 'deep': 9,\n",
              " 'models': 10,\n",
              " 'like': 11,\n",
              " 'a': 12,\n",
              " 'on': 13,\n",
              " 'is': 14,\n",
              " 'by': 15,\n",
              " 'networks': 16,\n",
              " 'training': 17,\n",
              " 'are': 18,\n",
              " 'tasks': 19,\n",
              " 'with': 20,\n",
              " 'model': 21,\n",
              " 'ml': 22,\n",
              " 'or': 23,\n",
              " 'image': 24,\n",
              " 'performance': 25,\n",
              " 'rnn': 26,\n",
              " 'layers': 27,\n",
              " 'feature': 28,\n",
              " 'used': 29,\n",
              " 'neural': 30,\n",
              " 'layer': 31,\n",
              " 'time': 32,\n",
              " 'text': 33,\n",
              " 'that': 34,\n",
              " 'uses': 35,\n",
              " 'input': 36,\n",
              " 'an': 37,\n",
              " 'each': 38,\n",
              " 'complex': 39,\n",
              " 'based': 40,\n",
              " 'rnns': 41,\n",
              " 'detection': 42,\n",
              " 'cnn': 43,\n",
              " 'language': 44,\n",
              " 'from': 45,\n",
              " 'patterns': 46,\n",
              " 'improve': 47,\n",
              " 'images': 48,\n",
              " 'processing': 49,\n",
              " 'use': 50,\n",
              " 'multiple': 51,\n",
              " 'cnns': 52,\n",
              " 'as': 53,\n",
              " 'recognition': 54,\n",
              " 'overfitting': 55,\n",
              " 'be': 56,\n",
              " 'sequences': 57,\n",
              " 'lstm': 58,\n",
              " 'can': 59,\n",
              " 'attention': 60,\n",
              " 'process': 61,\n",
              " 'network': 62,\n",
              " 'help': 63,\n",
              " 'new': 64,\n",
              " 'techniques': 65,\n",
              " 'reinforcement': 66,\n",
              " 'long': 67,\n",
              " 'into': 68,\n",
              " 'sequence': 69,\n",
              " 'machine': 70,\n",
              " 'sequential': 71,\n",
              " 'speech': 72,\n",
              " 'transfer': 73,\n",
              " 'ai': 74,\n",
              " 'more': 75,\n",
              " 'parameters': 76,\n",
              " 'term': 77,\n",
              " 'classification': 78,\n",
              " 'convolution': 79,\n",
              " 'objects': 80,\n",
              " 'convolutional': 81,\n",
              " 'such': 82,\n",
              " 'large': 83,\n",
              " 'learn': 84,\n",
              " 'across': 85,\n",
              " 'fewer': 86,\n",
              " 'series': 87,\n",
              " 'memory': 88,\n",
              " 'size': 89,\n",
              " 'has': 90,\n",
              " 'helps': 91,\n",
              " 'object': 92,\n",
              " 'segmentation': 93,\n",
              " 'parts': 94,\n",
              " 'systems': 95,\n",
              " 'maps': 96,\n",
              " 'neurons': 97,\n",
              " 'enabling': 98,\n",
              " 'recurrent': 99,\n",
              " 'vision': 100,\n",
              " 'nlp': 101,\n",
              " 'datasets': 102,\n",
              " 'computational': 103,\n",
              " 'one': 104,\n",
              " 'combines': 105,\n",
              " 'gradient': 106,\n",
              " 'human': 107,\n",
              " 'make': 108,\n",
              " 'their': 109,\n",
              " 'making': 110,\n",
              " 'during': 111,\n",
              " 'features': 112,\n",
              " 'improving': 113,\n",
              " 'translation': 114,\n",
              " 'using': 115,\n",
              " 'without': 116,\n",
              " 'filter': 117,\n",
              " 'video': 118,\n",
              " 'it': 119,\n",
              " 'involves': 120,\n",
              " 'weights': 121,\n",
              " 'analysis': 122,\n",
              " 'computer': 123,\n",
              " 'well': 124,\n",
              " 'dropout': 125,\n",
              " 'task': 126,\n",
              " 'another': 127,\n",
              " 'anomaly': 128,\n",
              " 'agents': 129,\n",
              " 'train': 130,\n",
              " 'have': 131,\n",
              " 'healthcare': 132,\n",
              " 'output': 133,\n",
              " 'between': 134,\n",
              " 'better': 135,\n",
              " 'spatial': 136,\n",
              " 'natural': 137,\n",
              " 'batch': 138,\n",
              " 'architecture': 139,\n",
              " 'focus': 140,\n",
              " 'important': 141,\n",
              " 'labels': 142,\n",
              " 'over': 143,\n",
              " 'reduce': 144,\n",
              " 'maintaining': 145,\n",
              " 'algorithms': 146,\n",
              " 'pooling': 147,\n",
              " 'temporal': 148,\n",
              " 'dependencies': 149,\n",
              " 'functions': 150,\n",
              " 'activation': 151,\n",
              " 'solve': 152,\n",
              " 'problems': 153,\n",
              " 'through': 154,\n",
              " 'requiring': 155,\n",
              " 'power': 156,\n",
              " 'where': 157,\n",
              " 'allows': 158,\n",
              " 'trained': 159,\n",
              " 'gans': 160,\n",
              " 'labeled': 161,\n",
              " 'applications': 162,\n",
              " 'predictions': 163,\n",
              " 'information': 164,\n",
              " 'them': 165,\n",
              " 'generation': 166,\n",
              " 'when': 167,\n",
              " 'often': 168,\n",
              " 'than': 169,\n",
              " 'within': 170,\n",
              " 'normalization': 171,\n",
              " 'hyperparameter': 172,\n",
              " 'accuracy': 173,\n",
              " 'at': 174,\n",
              " 'both': 175,\n",
              " 'modeling': 176,\n",
              " 'semantic': 177,\n",
              " 'identifies': 178,\n",
              " 'convolutions': 179,\n",
              " 'processes': 180,\n",
              " 'structure': 181,\n",
              " 'function': 182,\n",
              " 'non': 183,\n",
              " 'which': 184,\n",
              " 'errors': 185,\n",
              " 'typically': 186,\n",
              " 'requires': 187,\n",
              " 'fine': 188,\n",
              " 'unsupervised': 189,\n",
              " 'generative': 190,\n",
              " 'type': 191,\n",
              " 'descent': 192,\n",
              " 'effectively': 193,\n",
              " 'advancements': 194,\n",
              " 'especially': 195,\n",
              " 'gpus': 196,\n",
              " 'words': 197,\n",
              " 'hidden': 198,\n",
              " 'short': 199,\n",
              " 'vanishing': 200,\n",
              " 'lstms': 201,\n",
              " 'decisions': 202,\n",
              " 'random': 203,\n",
              " 'faster': 204,\n",
              " 'validation': 205,\n",
              " 'once': 206,\n",
              " 'specific': 207,\n",
              " 'supervised': 208,\n",
              " 'other': 209,\n",
              " 'actions': 210,\n",
              " 'speed': 211,\n",
              " 'optimization': 212,\n",
              " 'search': 213,\n",
              " 'efficiency': 214,\n",
              " 'extraction': 215,\n",
              " 'single': 216,\n",
              " 'forecasting': 217,\n",
              " 'future': 218,\n",
              " 'values': 219,\n",
              " 'machines': 220,\n",
              " 'driving': 221,\n",
              " 'value': 222,\n",
              " 'region': 223,\n",
              " 'map': 224,\n",
              " 'reduces': 225,\n",
              " 'capture': 226,\n",
              " 'resnet': 227,\n",
              " 'deeper': 228,\n",
              " 'decision': 229,\n",
              " 'predict': 230,\n",
              " 'relevant': 231,\n",
              " 'gru': 232,\n",
              " 'subset': 233,\n",
              " 'inspired': 234,\n",
              " 'artificial': 235,\n",
              " 'inputs': 236,\n",
              " 'results': 237,\n",
              " 'learns': 238,\n",
              " 'level': 239,\n",
              " 'edges': 240,\n",
              " 'relu': 241,\n",
              " 'linearity': 242,\n",
              " 'common': 243,\n",
              " 'include': 244,\n",
              " 'areas': 245,\n",
              " 'high': 246,\n",
              " 'significant': 247,\n",
              " 'regularization': 248,\n",
              " 'weight': 249,\n",
              " 'tuned': 250,\n",
              " 'reducing': 251,\n",
              " 'dimensionality': 252,\n",
              " 'reduction': 253,\n",
              " 'adversarial': 254,\n",
              " 'adam': 255,\n",
              " 'sgd': 256,\n",
              " 'crucial': 257,\n",
              " 'industries': 258,\n",
              " 'traditional': 259,\n",
              " 'different': 260,\n",
              " 'helping': 261,\n",
              " 'error': 262,\n",
              " 'minimize': 263,\n",
              " 'model’s': 264,\n",
              " 'designed': 265,\n",
              " 'detect': 266,\n",
              " 'allow': 267,\n",
              " 'problem': 268,\n",
              " 'environments': 269,\n",
              " 'too': 270,\n",
              " 'prevent': 271,\n",
              " 'randomly': 272,\n",
              " 'robust': 273,\n",
              " 'applying': 274,\n",
              " 'require': 275,\n",
              " 'allowing': 276,\n",
              " 'pre': 277,\n",
              " 'massive': 278,\n",
              " 'amounts': 279,\n",
              " 'medical': 280,\n",
              " 'rate': 281,\n",
              " 'cross': 282,\n",
              " 'assess': 283,\n",
              " 'early': 284,\n",
              " 'how': 285,\n",
              " 'predicts': 286,\n",
              " 'sentiment': 287,\n",
              " 'gpt': 288,\n",
              " 'mechanisms': 289,\n",
              " 'self': 290,\n",
              " 'predicting': 291,\n",
              " 'enables': 292,\n",
              " 'fields': 293,\n",
              " 'tuning': 294,\n",
              " 'steps': 295,\n",
              " 'methods': 296,\n",
              " 'combine': 297,\n",
              " 'understand': 298,\n",
              " 'increasing': 299,\n",
              " 'while': 300,\n",
              " 'privacy': 301,\n",
              " 'security': 302,\n",
              " 'content': 303,\n",
              " 'convert': 304,\n",
              " 'real': 305,\n",
              " 'style': 306,\n",
              " 'handle': 307,\n",
              " 'connected': 308,\n",
              " 'captioning': 309,\n",
              " 'generates': 310,\n",
              " 'pixel': 311,\n",
              " 'classifies': 312,\n",
              " 'create': 313,\n",
              " 'bias': 314,\n",
              " 'outcomes': 315,\n",
              " 'focuses': 316,\n",
              " 'development': 317,\n",
              " 'discovery': 318,\n",
              " 'converts': 319,\n",
              " 'ability': 320,\n",
              " 'maintain': 321,\n",
              " 'dimensions': 322,\n",
              " 'separable': 323,\n",
              " 'context': 324,\n",
              " 'connections': 325,\n",
              " 'sizes': 326,\n",
              " 'encoder': 327,\n",
              " 'decoder': 328,\n",
              " 'enhances': 329,\n",
              " 'improves': 330,\n",
              " 'bidirectional': 331,\n",
              " 'directions': 332,\n",
              " 'frames': 333,\n",
              " 'similar': 334,\n",
              " 'predictive': 335,\n",
              " 'brain': 336,\n",
              " 'simple': 337,\n",
              " 'shapes': 338,\n",
              " 'sigmoid': 339,\n",
              " 'introduce': 340,\n",
              " 'backpropagation': 341,\n",
              " 'adjust': 342,\n",
              " 'optimizing': 343,\n",
              " 'architectures': 344,\n",
              " 'but': 345,\n",
              " 'poorly': 346,\n",
              " 'extensive': 347,\n",
              " 'autoencoders': 348,\n",
              " 'generate': 349,\n",
              " 'synthetic': 350,\n",
              " 'optimizers': 351,\n",
              " 'stochastic': 352,\n",
              " 'hungry': 353,\n",
              " 'hardware': 354,\n",
              " 'tpus': 355,\n",
              " 'been': 356,\n",
              " 'critical': 357,\n",
              " 'frameworks': 358,\n",
              " 'accessible': 359,\n",
              " 'evolve': 360,\n",
              " 'entertainment': 361,\n",
              " 'sure': 362,\n",
              " 'concise': 363,\n",
              " 'lines': 364,\n",
              " 'line': 365,\n",
              " 'core': 366,\n",
              " 'enable': 367,\n",
              " 'computers': 368,\n",
              " 'consist': 369,\n",
              " 'raw': 370,\n",
              " 'makes': 371,\n",
              " 'minimizing': 372,\n",
              " 'predicted': 373,\n",
              " 'actual': 374,\n",
              " 'outputs': 375,\n",
              " 'loss': 376,\n",
              " 'you': 377,\n",
              " 'identifying': 378,\n",
              " 'textures': 379,\n",
              " 'suited': 380,\n",
              " 'ideal': 381,\n",
              " 'two': 382,\n",
              " 'popular': 383,\n",
              " 'music': 384,\n",
              " 'efficient': 385,\n",
              " 'representations': 386,\n",
              " 'occurs': 387,\n",
              " 'including': 388,\n",
              " 'disables': 389,\n",
              " 'increases': 390,\n",
              " 'specialized': 391,\n",
              " 'much': 392,\n",
              " 'effective': 393,\n",
              " 'expensive': 394,\n",
              " 'providing': 395,\n",
              " 'sets': 396,\n",
              " 'stopping': 397,\n",
              " 'prevents': 398,\n",
              " 'set': 399,\n",
              " 'revolutionized': 400,\n",
              " 'seen': 401,\n",
              " 'state': 402,\n",
              " 'art': 403,\n",
              " 'understanding': 404,\n",
              " 'unlabeled': 405,\n",
              " 'rewards': 406,\n",
              " 'finance': 407,\n",
              " 'resources': 408,\n",
              " 'initialization': 409,\n",
              " 'grid': 410,\n",
              " 'evaluated': 411,\n",
              " 'metrics': 412,\n",
              " 'precision': 413,\n",
              " 'positives': 414,\n",
              " 'step': 415,\n",
              " 'preprocessing': 416,\n",
              " 'transforming': 417,\n",
              " 'multi': 418,\n",
              " 'related': 419,\n",
              " 'knowledge': 420,\n",
              " 'ensemble': 421,\n",
              " 'pruning': 422,\n",
              " 'quantization': 423,\n",
              " 'interpretability': 424,\n",
              " 'trust': 425,\n",
              " 'transparency': 426,\n",
              " 'federated': 427,\n",
              " 'voice': 428,\n",
              " 'assistants': 429,\n",
              " 'translate': 430,\n",
              " 'applies': 431,\n",
              " 'artistic': 432,\n",
              " 'various': 433,\n",
              " 'types': 434,\n",
              " 'adjusting': 435,\n",
              " 'robotics': 436,\n",
              " 'identify': 437,\n",
              " 'unusual': 438,\n",
              " 'useful': 439,\n",
              " 'autonomous': 440,\n",
              " 'faces': 441,\n",
              " 'interpret': 442,\n",
              " 'pattern': 443,\n",
              " 'lead': 444,\n",
              " 'discriminatory': 445,\n",
              " 'deployment': 446,\n",
              " 'ensuring': 447,\n",
              " 'automated': 448,\n",
              " 'automl': 449,\n",
              " 'automating': 450,\n",
              " 'engineering': 451,\n",
              " 'diagnostics': 452,\n",
              " 'drug': 453,\n",
              " 'analyze': 454,\n",
              " 'detecting': 455,\n",
              " 'cars': 456,\n",
              " 'intelligent': 457,\n",
              " 'user': 458,\n",
              " 'generalization': 459,\n",
              " 'unseen': 460,\n",
              " 'zero': 461,\n",
              " 'shot': 462,\n",
              " 'they': 463,\n",
              " 'leveraging': 464,\n",
              " 'potential': 465,\n",
              " 'being': 466,\n",
              " 'less': 467,\n",
              " 'adds': 468,\n",
              " 'introduces': 469,\n",
              " 'maxpooling': 470,\n",
              " 'averagepooling': 471,\n",
              " 'sub': 472,\n",
              " 'average': 473,\n",
              " 'fully': 474,\n",
              " 'previous': 475,\n",
              " 'next': 476,\n",
              " 'global': 477,\n",
              " 'excel': 478,\n",
              " 'depthwise': 479,\n",
              " 'cost': 480,\n",
              " 'dilated': 481,\n",
              " 'residual': 482,\n",
              " 'skip': 483,\n",
              " 'alexnet': 484,\n",
              " 'stacked': 485,\n",
              " 'devices': 486,\n",
              " 'gradients': 487,\n",
              " 'bounding': 488,\n",
              " 'boxes': 489,\n",
              " 'detects': 490,\n",
              " 'scale': 491,\n",
              " 'pyramid': 492,\n",
              " 'captures': 493,\n",
              " 'varying': 494,\n",
              " 'mechanism': 495,\n",
              " 'enhancing': 496,\n",
              " 'field': 497,\n",
              " 'hierarchical': 498,\n",
              " 'compared': 499,\n",
              " 'word': 500,\n",
              " 'vector': 501,\n",
              " 'forward': 502,\n",
              " 'sentence': 503,\n",
              " 'gated': 504,\n",
              " 'unit': 505,\n",
              " 'capturing': 506,\n",
              " 'simpler': 507,\n",
              " 'stacking': 508,\n",
              " 'sentences': 509,\n",
              " 'historical': 510,\n",
              " 'seq2seq': 511,\n",
              " 'vs': 512,\n",
              " 'grus': 513,\n",
              " 'recognize': 514,\n",
              " 'focusing': 515,\n",
              " 'clustering': 516,\n",
              " 'most': 517,\n",
              " 'its': 518,\n",
              " 'generalize': 519,\n",
              " 'testing': 520,\n",
              " 'support': 521,\n",
              " 'platforms': 522,\n",
              " 'ethical': 523,\n",
              " 'ensure': 524,\n",
              " 'fraud': 525,\n",
              " 'points': 526,\n",
              " 'selection': 527,\n",
              " 'called': 528,\n",
              " 'hence': 529,\n",
              " 'mathematical': 530,\n",
              " 'pass': 531,\n",
              " 'subsequent': 532,\n",
              " 'higher': 533,\n",
              " 'excels': 534,\n",
              " 'dimensional': 535,\n",
              " 'challenge': 536,\n",
              " 'performs': 537,\n",
              " 'decay': 538,\n",
              " 'mitigate': 539,\n",
              " 'need': 540,\n",
              " 'samples': 541,\n",
              " 'accurately': 542,\n",
              " \"learning's\": 543,\n",
              " 'progress': 544,\n",
              " 'tensorflow': 545,\n",
              " 'pytorch': 546,\n",
              " 'keras': 547,\n",
              " 'made': 548,\n",
              " 'manageable': 549,\n",
              " 'continues': 550,\n",
              " 'pushing': 551,\n",
              " 'boundaries': 552,\n",
              " 'here’s': 553,\n",
              " 'overview': 554,\n",
              " 'containing': 555,\n",
              " 'mimics': 556,\n",
              " 'brain’s': 557,\n",
              " 'anns': 558,\n",
              " 'classifications': 559,\n",
              " 'extracting': 560,\n",
              " 'would': 561,\n",
              " 'difficult': 562,\n",
              " 'idea': 563,\n",
              " 'automatically': 564,\n",
              " 'exposure': 565,\n",
              " 'representing': 566,\n",
              " 'levels': 567,\n",
              " 'abstraction': 568,\n",
              " 'receives': 569,\n",
              " 'passed': 570,\n",
              " 'adjusts': 571,\n",
              " 'updating': 572,\n",
              " 'iteratively': 573,\n",
              " 'thrives': 574,\n",
              " 'big': 575,\n",
              " 'provide': 576,\n",
              " 'hierarchies': 577,\n",
              " 'loops': 578,\n",
              " 'persist': 579,\n",
              " 'solves': 580,\n",
              " 'cells': 581,\n",
              " 'store': 582,\n",
              " 'durations': 583,\n",
              " 'overcoming': 584,\n",
              " 'limitations': 585,\n",
              " 'generator': 586,\n",
              " 'discriminator': 587,\n",
              " 'creating': 588,\n",
              " 'videos': 589,\n",
              " 'even': 590,\n",
              " 'noise': 591,\n",
              " 'generalizes': 592,\n",
              " 'l2': 593,\n",
              " 'penalizing': 594,\n",
              " 'overly': 595,\n",
              " 'forcing': 596,\n",
              " 'augmentation': 597,\n",
              " 'artificially': 598,\n",
              " 'dataset': 599,\n",
              " 'transformations': 600,\n",
              " 'rotations': 601,\n",
              " 'flips': 602,\n",
              " 'accelerate': 603,\n",
              " 'parallelize': 604,\n",
              " 'computations': 605,\n",
              " 'cpus': 606,\n",
              " 'leverages': 607,\n",
              " 'tunes': 608,\n",
              " 'saving': 609,\n",
              " 'proven': 610,\n",
              " 'limited': 611,\n",
              " 'labeling': 612,\n",
              " 'consuming': 613,\n",
              " 'update': 614,\n",
              " 'benefits': 615,\n",
              " 'momentum': 616,\n",
              " 'adaptive': 617,\n",
              " 'rates': 618,\n",
              " 'hyperparameters': 619,\n",
              " 'must': 620,\n",
              " 'carefully': 621,\n",
              " 'optimal': 622,\n",
              " 'dividing': 623,\n",
              " 'halting': 624,\n",
              " 'stops': 625,\n",
              " 'mean': 626,\n",
              " 'squared': 627,\n",
              " 'mse': 628,\n",
              " 'entropy': 629,\n",
              " 'evaluate': 630,\n",
              " 'great': 631,\n",
              " 'improvements': 632,\n",
              " 'greatly': 633,\n",
              " 'advanced': 634,\n",
              " 'transformers': 635,\n",
              " 'become': 636,\n",
              " 'foundation': 637,\n",
              " 'bert': 638,\n",
              " 'vast': 639,\n",
              " 'corpora': 640,\n",
              " 'wide': 641,\n",
              " 'range': 642,\n",
              " '3': 643,\n",
              " 'transformer': 644,\n",
              " 'achieved': 645,\n",
              " 'interacting': 646,\n",
              " 'environment': 647,\n",
              " 'receiving': 648,\n",
              " 'cybersecurity': 649,\n",
              " 'amount': 650,\n",
              " 'stabilize': 651,\n",
              " 'up': 652,\n",
              " 'normalizing': 653,\n",
              " 'activations': 654,\n",
              " 'mini': 655,\n",
              " 'xavier': 656,\n",
              " 'he': 657,\n",
              " 'start': 658,\n",
              " 'balanced': 659,\n",
              " 'find': 660,\n",
              " 'best': 661,\n",
              " 'recall': 662,\n",
              " 'f1': 663,\n",
              " 'score': 664,\n",
              " 'confusion': 665,\n",
              " 'matrices': 666,\n",
              " 'visualize': 667,\n",
              " 'showing': 668,\n",
              " 'true': 669,\n",
              " 'false': 670,\n",
              " 'experimenting': 671,\n",
              " 'configurations': 672,\n",
              " 'schedules': 673,\n",
              " 'convergence': 674,\n",
              " 'affects': 675,\n",
              " 'processed': 676,\n",
              " 'influencing': 677,\n",
              " 'scaling': 678,\n",
              " 'selecting': 679,\n",
              " 'meaningful': 680,\n",
              " 'simultaneously': 681,\n",
              " 'sharing': 682,\n",
              " 'overall': 683,\n",
              " 'compression': 684,\n",
              " 'explainable': 685,\n",
              " 'xai': 686,\n",
              " 'aims': 687,\n",
              " 'understandable': 688,\n",
              " 'humans': 689,\n",
              " 'decentralized': 690,\n",
              " 'sources': 691,\n",
              " 'easier': 692,\n",
              " 'build': 693,\n",
              " 'dependent': 694,\n",
              " 'stock': 695,\n",
              " 'prices': 696,\n",
              " 'weather': 697,\n",
              " 'assigning': 698,\n",
              " 'spoken': 699,\n",
              " 'vice': 700,\n",
              " 'versa': 701,\n",
              " 'siri': 702,\n",
              " 'alexa': 703,\n",
              " 'rely': 704,\n",
              " 'response': 705,\n",
              " 'typing': 706,\n",
              " 'creative': 707,\n",
              " 'biological': 708,\n",
              " 'mathematically': 709,\n",
              " 'forming': 710,\n",
              " 'connection': 711,\n",
              " 'difference': 712,\n",
              " 'past': 713,\n",
              " 'teach': 714,\n",
              " 'perform': 715,\n",
              " 'manipulation': 716,\n",
              " 'navigation': 717,\n",
              " 'fraudulent': 718,\n",
              " 'activity': 719,\n",
              " 'system': 720,\n",
              " 'failures': 721,\n",
              " 'descriptive': 722,\n",
              " 'combining': 723,\n",
              " 'vehicles': 724,\n",
              " 'robotic': 725,\n",
              " 'robots': 726,\n",
              " 'surroundings': 727,\n",
              " 'distribution': 728,\n",
              " 'existing': 729,\n",
              " 'particularly': 730,\n",
              " 'diverse': 731,\n",
              " 'biology': 732,\n",
              " 'marketing': 733,\n",
              " 'computationally': 734,\n",
              " 'ethics': 735,\n",
              " 'consideration': 736,\n",
              " 'deploying': 737,\n",
              " 'sensitive': 738,\n",
              " 'law': 739,\n",
              " 'enforcement': 740,\n",
              " 'unfair': 741,\n",
              " 'necessitating': 742,\n",
              " 'careful': 743,\n",
              " 'safety': 744,\n",
              " 'act': 745,\n",
              " 'alignment': 746,\n",
              " 'priorities': 747,\n",
              " 'governance': 748,\n",
              " 'establishing': 749,\n",
              " 'policies': 750,\n",
              " 'guidelines': 751,\n",
              " 'responsible': 752,\n",
              " 'simplify': 753,\n",
              " 'creation': 754,\n",
              " 'enabled': 755,\n",
              " 'major': 756,\n",
              " 'imaging': 757,\n",
              " 'x': 758,\n",
              " 'rays': 759,\n",
              " 'mris': 760,\n",
              " 'diseases': 761,\n",
              " 'cancer': 762,\n",
              " 'navigate': 763,\n",
              " 'autonomously': 764,\n",
              " 'integral': 765,\n",
              " 'productivity': 766,\n",
              " 'experience': 767,\n",
              " 'continuously': 768,\n",
              " 'evolving': 769,\n",
              " 'researchers': 770,\n",
              " 'exploring': 771,\n",
              " 'removing': 772,\n",
              " 'unnecessary': 773,\n",
              " 'floating': 774,\n",
              " 'point': 775,\n",
              " 'numbers': 776,\n",
              " 'lower': 777,\n",
              " 'formats': 778,\n",
              " 'usage': 779,\n",
              " 'costs': 780,\n",
              " 'test': 781,\n",
              " 'prevention': 782,\n",
              " 'balance': 783,\n",
              " 'complexity': 784,\n",
              " \"haven't\": 785,\n",
              " 'prior': 786,\n",
              " 'holds': 787,\n",
              " 'immense': 788,\n",
              " 'solving': 789,\n",
              " 'climate': 790,\n",
              " 'science': 791,\n",
              " 'space': 792,\n",
              " 'exploration': 793,\n",
              " 'here': 794,\n",
              " 'list': 795,\n",
              " 'about': 796,\n",
              " 'equal': 797,\n",
              " 'conv': 798,\n",
              " 'slides': 799,\n",
              " 'stride': 800,\n",
              " 'defines': 801,\n",
              " 'moves': 802,\n",
              " 'padding': 803,\n",
              " 'extra': 804,\n",
              " 'pixels': 805,\n",
              " 'around': 806,\n",
              " 'selects': 807,\n",
              " 'maximum': 808,\n",
              " 'takes': 809,\n",
              " 'fc': 810,\n",
              " 'connects': 811,\n",
              " 'every': 812,\n",
              " 'neuron': 813,\n",
              " 'normalizes': 814,\n",
              " 'stability': 815,\n",
              " 'averaging': 816,\n",
              " 'entire': 817,\n",
              " 'stages': 818,\n",
              " 'spaced': 819,\n",
              " 'out': 820,\n",
              " 'filters': 821,\n",
              " 'larger': 822,\n",
              " '1x1': 823,\n",
              " 'transposed': 824,\n",
              " 'deconvolutions': 825,\n",
              " 'upsample': 826,\n",
              " 'apply': 827,\n",
              " 'separate': 828,\n",
              " 'width': 829,\n",
              " 'height': 830,\n",
              " 'bypass': 831,\n",
              " 'inception': 832,\n",
              " 'scales': 833,\n",
              " 'first': 834,\n",
              " 'vggnet': 835,\n",
              " 'smaller': 836,\n",
              " '3x3': 837,\n",
              " 'lenet': 838,\n",
              " 'handwritten': 839,\n",
              " 'digit': 840,\n",
              " 'squeezenet': 841,\n",
              " 'number': 842,\n",
              " 'mobilenet': 843,\n",
              " 'optimized': 844,\n",
              " 'mobile': 845,\n",
              " 'operations': 846,\n",
              " 'densenet': 847,\n",
              " 'dense': 848,\n",
              " 'reuse': 849,\n",
              " 'flow': 850,\n",
              " 'xception': 851,\n",
              " 'u': 852,\n",
              " 'net': 853,\n",
              " 'symmetric': 854,\n",
              " 'r': 855,\n",
              " 'proposal': 856,\n",
              " 'rpn': 857,\n",
              " 'yolo': 858,\n",
              " 'only': 859,\n",
              " 'look': 860,\n",
              " 'directly': 861,\n",
              " 'ssd': 862,\n",
              " 'multibox': 863,\n",
              " 'detector': 864,\n",
              " 'fpn': 865,\n",
              " 'top': 866,\n",
              " 'down': 867,\n",
              " 'states': 868,\n",
              " 'timesteps': 869,\n",
              " 'crnn': 870,\n",
              " 'summarizes': 871,\n",
              " '1d': 872,\n",
              " '3d': 873,\n",
              " 'extends': 874,\n",
              " 'three': 875,\n",
              " 'commonly': 876,\n",
              " 'regions': 877,\n",
              " 'resnext': 878,\n",
              " 'split': 879,\n",
              " 'transform': 880,\n",
              " 'merge': 881,\n",
              " 'strategy': 882,\n",
              " 'styles': 883,\n",
              " 'onto': 884,\n",
              " 'handles': 885,\n",
              " 'resizing': 886,\n",
              " 'receptive': 887,\n",
              " 'low': 888,\n",
              " '50': 889,\n",
              " 'lightweight': 890,\n",
              " 'variants': 891,\n",
              " 'introduced': 892,\n",
              " 'represent': 893,\n",
              " 'after': 894,\n",
              " 'standardizes': 895,\n",
              " 'stable': 896,\n",
              " 'fraction': 897,\n",
              " 'units': 898,\n",
              " 'downsample': 899,\n",
              " 'comes': 900,\n",
              " 'end': 901,\n",
              " 'remembers': 902,\n",
              " 'embedding': 903,\n",
              " 'backward': 904,\n",
              " 'scenes': 905,\n",
              " 'class': 906,\n",
              " 'finds': 907,\n",
              " 'category': 908,\n",
              " 'face': 909,\n",
              " 'instance': 910,\n",
              " 'interest': 911,\n",
              " 'classify': 912,\n",
              " 'abnormal': 913,\n",
              " 'simplified': 914,\n",
              " 'gating': 915,\n",
              " 'mitigating': 916,\n",
              " 'limits': 917,\n",
              " 'audio': 918,\n",
              " 'signals': 919,\n",
              " 'learned': 920,\n",
              " 'lengths': 921,\n",
              " 'han': 922,\n",
              " 'document': 923,\n",
              " 'determine': 924,\n",
              " 'essential': 925,\n",
              " 'translates': 926,\n",
              " 'languages': 927,\n",
              " 'structures': 928,\n",
              " 'textual': 929,\n",
              " 'descriptions': 930,\n",
              " 'sequentially': 931,\n",
              " 'summarization': 932,\n",
              " 'named': 933,\n",
              " 'entity': 934,\n",
              " 'entities': 935,\n",
              " 'names': 936,\n",
              " 'dates': 937,\n",
              " 'reverse': 938,\n",
              " 'involve': 939,\n",
              " 'tcn': 940,\n",
              " 'replace': 941,\n",
              " 'explicitly': 942,\n",
              " 'programmed': 943,\n",
              " 'association': 944,\n",
              " 'trains': 945,\n",
              " 'trial': 946,\n",
              " 'maximize': 947,\n",
              " 'dynamic': 948,\n",
              " 'quality': 949,\n",
              " 'quantity': 950,\n",
              " 'plays': 951,\n",
              " 'role': 952,\n",
              " 'determining': 953,\n",
              " 'aspects': 954,\n",
              " 'valuable': 955,\n",
              " 'losing': 956,\n",
              " 'underfitting': 957,\n",
              " 'happens': 958,\n",
              " 'fails': 959,\n",
              " 'underlying': 960,\n",
              " \"model's\": 961,\n",
              " 'splitting': 962,\n",
              " 'subsets': 963,\n",
              " 'linear': 964,\n",
              " 'regression': 965,\n",
              " 'trees': 966,\n",
              " 'forests': 967,\n",
              " 'branch': 968,\n",
              " 'focused': 969,\n",
              " 'recommendation': 970,\n",
              " 'netflix': 971,\n",
              " 'amazon': 972,\n",
              " 'suggesting': 973,\n",
              " 'behavior': 974,\n",
              " 'key': 975,\n",
              " 'application': 976,\n",
              " 'visual': 977,\n",
              " 'concerns': 978,\n",
              " 'algorithmic': 979,\n",
              " 'misuse': 980,\n",
              " 'surveillance': 981,\n",
              " 'explainability': 982,\n",
              " 'deployed': 983,\n",
              " 'cloud': 984,\n",
              " 'scalability': 985,\n",
              " 'access': 986,\n",
              " 'powerful': 987,\n",
              " 'optimizes': 988,\n",
              " 'successful': 989,\n",
              " 'gaming': 990,\n",
              " 'revolutionizing': 991,\n",
              " 'automation': 992,\n",
              " 'analytics': 993,\n",
              " 'handling': 994,\n",
              " 'missing': 995,\n",
              " 'vital': 996,\n",
              " 'biased': 997,\n",
              " 'potentially': 998,\n",
              " 'reinforcing': 999,\n",
              " 'stereotypes': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgILByVevulx",
        "outputId": "ed1d7c99-df0e-4a75-8320-064b4f1f91a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'and': 1, 'to': 2, 'the': 3, 'learning': 4, 'data': 5, 'for': 6, 'in': 7, 'of': 8, 'deep': 9, 'models': 10, 'like': 11, 'a': 12, 'on': 13, 'is': 14, 'by': 15, 'networks': 16, 'training': 17, 'are': 18, 'tasks': 19, 'with': 20, 'model': 21, 'ml': 22, 'or': 23, 'image': 24, 'performance': 25, 'rnn': 26, 'layers': 27, 'feature': 28, 'used': 29, 'neural': 30, 'layer': 31, 'time': 32, 'text': 33, 'that': 34, 'uses': 35, 'input': 36, 'an': 37, 'each': 38, 'complex': 39, 'based': 40, 'rnns': 41, 'detection': 42, 'cnn': 43, 'language': 44, 'from': 45, 'patterns': 46, 'improve': 47, 'images': 48, 'processing': 49, 'use': 50, 'multiple': 51, 'cnns': 52, 'as': 53, 'recognition': 54, 'overfitting': 55, 'be': 56, 'sequences': 57, 'lstm': 58, 'can': 59, 'attention': 60, 'process': 61, 'network': 62, 'help': 63, 'new': 64, 'techniques': 65, 'reinforcement': 66, 'long': 67, 'into': 68, 'sequence': 69, 'machine': 70, 'sequential': 71, 'speech': 72, 'transfer': 73, 'ai': 74, 'more': 75, 'parameters': 76, 'term': 77, 'classification': 78, 'convolution': 79, 'objects': 80, 'convolutional': 81, 'such': 82, 'large': 83, 'learn': 84, 'across': 85, 'fewer': 86, 'series': 87, 'memory': 88, 'size': 89, 'has': 90, 'helps': 91, 'object': 92, 'segmentation': 93, 'parts': 94, 'systems': 95, 'maps': 96, 'neurons': 97, 'enabling': 98, 'recurrent': 99, 'vision': 100, 'nlp': 101, 'datasets': 102, 'computational': 103, 'one': 104, 'combines': 105, 'gradient': 106, 'human': 107, 'make': 108, 'their': 109, 'making': 110, 'during': 111, 'features': 112, 'improving': 113, 'translation': 114, 'using': 115, 'without': 116, 'filter': 117, 'video': 118, 'it': 119, 'involves': 120, 'weights': 121, 'analysis': 122, 'computer': 123, 'well': 124, 'dropout': 125, 'task': 126, 'another': 127, 'anomaly': 128, 'agents': 129, 'train': 130, 'have': 131, 'healthcare': 132, 'output': 133, 'between': 134, 'better': 135, 'spatial': 136, 'natural': 137, 'batch': 138, 'architecture': 139, 'focus': 140, 'important': 141, 'labels': 142, 'over': 143, 'reduce': 144, 'maintaining': 145, 'algorithms': 146, 'pooling': 147, 'temporal': 148, 'dependencies': 149, 'functions': 150, 'activation': 151, 'solve': 152, 'problems': 153, 'through': 154, 'requiring': 155, 'power': 156, 'where': 157, 'allows': 158, 'trained': 159, 'gans': 160, 'labeled': 161, 'applications': 162, 'predictions': 163, 'information': 164, 'them': 165, 'generation': 166, 'when': 167, 'often': 168, 'than': 169, 'within': 170, 'normalization': 171, 'hyperparameter': 172, 'accuracy': 173, 'at': 174, 'both': 175, 'modeling': 176, 'semantic': 177, 'identifies': 178, 'convolutions': 179, 'processes': 180, 'structure': 181, 'function': 182, 'non': 183, 'which': 184, 'errors': 185, 'typically': 186, 'requires': 187, 'fine': 188, 'unsupervised': 189, 'generative': 190, 'type': 191, 'descent': 192, 'effectively': 193, 'advancements': 194, 'especially': 195, 'gpus': 196, 'words': 197, 'hidden': 198, 'short': 199, 'vanishing': 200, 'lstms': 201, 'decisions': 202, 'random': 203, 'faster': 204, 'validation': 205, 'once': 206, 'specific': 207, 'supervised': 208, 'other': 209, 'actions': 210, 'speed': 211, 'optimization': 212, 'search': 213, 'efficiency': 214, 'extraction': 215, 'single': 216, 'forecasting': 217, 'future': 218, 'values': 219, 'machines': 220, 'driving': 221, 'value': 222, 'region': 223, 'map': 224, 'reduces': 225, 'capture': 226, 'resnet': 227, 'deeper': 228, 'decision': 229, 'predict': 230, 'relevant': 231, 'gru': 232, 'subset': 233, 'inspired': 234, 'artificial': 235, 'inputs': 236, 'results': 237, 'learns': 238, 'level': 239, 'edges': 240, 'relu': 241, 'linearity': 242, 'common': 243, 'include': 244, 'areas': 245, 'high': 246, 'significant': 247, 'regularization': 248, 'weight': 249, 'tuned': 250, 'reducing': 251, 'dimensionality': 252, 'reduction': 253, 'adversarial': 254, 'adam': 255, 'sgd': 256, 'crucial': 257, 'industries': 258, 'traditional': 259, 'different': 260, 'helping': 261, 'error': 262, 'minimize': 263, 'model’s': 264, 'designed': 265, 'detect': 266, 'allow': 267, 'problem': 268, 'environments': 269, 'too': 270, 'prevent': 271, 'randomly': 272, 'robust': 273, 'applying': 274, 'require': 275, 'allowing': 276, 'pre': 277, 'massive': 278, 'amounts': 279, 'medical': 280, 'rate': 281, 'cross': 282, 'assess': 283, 'early': 284, 'how': 285, 'predicts': 286, 'sentiment': 287, 'gpt': 288, 'mechanisms': 289, 'self': 290, 'predicting': 291, 'enables': 292, 'fields': 293, 'tuning': 294, 'steps': 295, 'methods': 296, 'combine': 297, 'understand': 298, 'increasing': 299, 'while': 300, 'privacy': 301, 'security': 302, 'content': 303, 'convert': 304, 'real': 305, 'style': 306, 'handle': 307, 'connected': 308, 'captioning': 309, 'generates': 310, 'pixel': 311, 'classifies': 312, 'create': 313, 'bias': 314, 'outcomes': 315, 'focuses': 316, 'development': 317, 'discovery': 318, 'converts': 319, 'ability': 320, 'maintain': 321, 'dimensions': 322, 'separable': 323, 'context': 324, 'connections': 325, 'sizes': 326, 'encoder': 327, 'decoder': 328, 'enhances': 329, 'improves': 330, 'bidirectional': 331, 'directions': 332, 'frames': 333, 'similar': 334, 'predictive': 335, 'brain': 336, 'simple': 337, 'shapes': 338, 'sigmoid': 339, 'introduce': 340, 'backpropagation': 341, 'adjust': 342, 'optimizing': 343, 'architectures': 344, 'but': 345, 'poorly': 346, 'extensive': 347, 'autoencoders': 348, 'generate': 349, 'synthetic': 350, 'optimizers': 351, 'stochastic': 352, 'hungry': 353, 'hardware': 354, 'tpus': 355, 'been': 356, 'critical': 357, 'frameworks': 358, 'accessible': 359, 'evolve': 360, 'entertainment': 361, 'sure': 362, 'concise': 363, 'lines': 364, 'line': 365, 'core': 366, 'enable': 367, 'computers': 368, 'consist': 369, 'raw': 370, 'makes': 371, 'minimizing': 372, 'predicted': 373, 'actual': 374, 'outputs': 375, 'loss': 376, 'you': 377, 'identifying': 378, 'textures': 379, 'suited': 380, 'ideal': 381, 'two': 382, 'popular': 383, 'music': 384, 'efficient': 385, 'representations': 386, 'occurs': 387, 'including': 388, 'disables': 389, 'increases': 390, 'specialized': 391, 'much': 392, 'effective': 393, 'expensive': 394, 'providing': 395, 'sets': 396, 'stopping': 397, 'prevents': 398, 'set': 399, 'revolutionized': 400, 'seen': 401, 'state': 402, 'art': 403, 'understanding': 404, 'unlabeled': 405, 'rewards': 406, 'finance': 407, 'resources': 408, 'initialization': 409, 'grid': 410, 'evaluated': 411, 'metrics': 412, 'precision': 413, 'positives': 414, 'step': 415, 'preprocessing': 416, 'transforming': 417, 'multi': 418, 'related': 419, 'knowledge': 420, 'ensemble': 421, 'pruning': 422, 'quantization': 423, 'interpretability': 424, 'trust': 425, 'transparency': 426, 'federated': 427, 'voice': 428, 'assistants': 429, 'translate': 430, 'applies': 431, 'artistic': 432, 'various': 433, 'types': 434, 'adjusting': 435, 'robotics': 436, 'identify': 437, 'unusual': 438, 'useful': 439, 'autonomous': 440, 'faces': 441, 'interpret': 442, 'pattern': 443, 'lead': 444, 'discriminatory': 445, 'deployment': 446, 'ensuring': 447, 'automated': 448, 'automl': 449, 'automating': 450, 'engineering': 451, 'diagnostics': 452, 'drug': 453, 'analyze': 454, 'detecting': 455, 'cars': 456, 'intelligent': 457, 'user': 458, 'generalization': 459, 'unseen': 460, 'zero': 461, 'shot': 462, 'they': 463, 'leveraging': 464, 'potential': 465, 'being': 466, 'less': 467, 'adds': 468, 'introduces': 469, 'maxpooling': 470, 'averagepooling': 471, 'sub': 472, 'average': 473, 'fully': 474, 'previous': 475, 'next': 476, 'global': 477, 'excel': 478, 'depthwise': 479, 'cost': 480, 'dilated': 481, 'residual': 482, 'skip': 483, 'alexnet': 484, 'stacked': 485, 'devices': 486, 'gradients': 487, 'bounding': 488, 'boxes': 489, 'detects': 490, 'scale': 491, 'pyramid': 492, 'captures': 493, 'varying': 494, 'mechanism': 495, 'enhancing': 496, 'field': 497, 'hierarchical': 498, 'compared': 499, 'word': 500, 'vector': 501, 'forward': 502, 'sentence': 503, 'gated': 504, 'unit': 505, 'capturing': 506, 'simpler': 507, 'stacking': 508, 'sentences': 509, 'historical': 510, 'seq2seq': 511, 'vs': 512, 'grus': 513, 'recognize': 514, 'focusing': 515, 'clustering': 516, 'most': 517, 'its': 518, 'generalize': 519, 'testing': 520, 'support': 521, 'platforms': 522, 'ethical': 523, 'ensure': 524, 'fraud': 525, 'points': 526, 'selection': 527, 'called': 528, 'hence': 529, 'mathematical': 530, 'pass': 531, 'subsequent': 532, 'higher': 533, 'excels': 534, 'dimensional': 535, 'challenge': 536, 'performs': 537, 'decay': 538, 'mitigate': 539, 'need': 540, 'samples': 541, 'accurately': 542, \"learning's\": 543, 'progress': 544, 'tensorflow': 545, 'pytorch': 546, 'keras': 547, 'made': 548, 'manageable': 549, 'continues': 550, 'pushing': 551, 'boundaries': 552, 'here’s': 553, 'overview': 554, 'containing': 555, 'mimics': 556, 'brain’s': 557, 'anns': 558, 'classifications': 559, 'extracting': 560, 'would': 561, 'difficult': 562, 'idea': 563, 'automatically': 564, 'exposure': 565, 'representing': 566, 'levels': 567, 'abstraction': 568, 'receives': 569, 'passed': 570, 'adjusts': 571, 'updating': 572, 'iteratively': 573, 'thrives': 574, 'big': 575, 'provide': 576, 'hierarchies': 577, 'loops': 578, 'persist': 579, 'solves': 580, 'cells': 581, 'store': 582, 'durations': 583, 'overcoming': 584, 'limitations': 585, 'generator': 586, 'discriminator': 587, 'creating': 588, 'videos': 589, 'even': 590, 'noise': 591, 'generalizes': 592, 'l2': 593, 'penalizing': 594, 'overly': 595, 'forcing': 596, 'augmentation': 597, 'artificially': 598, 'dataset': 599, 'transformations': 600, 'rotations': 601, 'flips': 602, 'accelerate': 603, 'parallelize': 604, 'computations': 605, 'cpus': 606, 'leverages': 607, 'tunes': 608, 'saving': 609, 'proven': 610, 'limited': 611, 'labeling': 612, 'consuming': 613, 'update': 614, 'benefits': 615, 'momentum': 616, 'adaptive': 617, 'rates': 618, 'hyperparameters': 619, 'must': 620, 'carefully': 621, 'optimal': 622, 'dividing': 623, 'halting': 624, 'stops': 625, 'mean': 626, 'squared': 627, 'mse': 628, 'entropy': 629, 'evaluate': 630, 'great': 631, 'improvements': 632, 'greatly': 633, 'advanced': 634, 'transformers': 635, 'become': 636, 'foundation': 637, 'bert': 638, 'vast': 639, 'corpora': 640, 'wide': 641, 'range': 642, '3': 643, 'transformer': 644, 'achieved': 645, 'interacting': 646, 'environment': 647, 'receiving': 648, 'cybersecurity': 649, 'amount': 650, 'stabilize': 651, 'up': 652, 'normalizing': 653, 'activations': 654, 'mini': 655, 'xavier': 656, 'he': 657, 'start': 658, 'balanced': 659, 'find': 660, 'best': 661, 'recall': 662, 'f1': 663, 'score': 664, 'confusion': 665, 'matrices': 666, 'visualize': 667, 'showing': 668, 'true': 669, 'false': 670, 'experimenting': 671, 'configurations': 672, 'schedules': 673, 'convergence': 674, 'affects': 675, 'processed': 676, 'influencing': 677, 'scaling': 678, 'selecting': 679, 'meaningful': 680, 'simultaneously': 681, 'sharing': 682, 'overall': 683, 'compression': 684, 'explainable': 685, 'xai': 686, 'aims': 687, 'understandable': 688, 'humans': 689, 'decentralized': 690, 'sources': 691, 'easier': 692, 'build': 693, 'dependent': 694, 'stock': 695, 'prices': 696, 'weather': 697, 'assigning': 698, 'spoken': 699, 'vice': 700, 'versa': 701, 'siri': 702, 'alexa': 703, 'rely': 704, 'response': 705, 'typing': 706, 'creative': 707, 'biological': 708, 'mathematically': 709, 'forming': 710, 'connection': 711, 'difference': 712, 'past': 713, 'teach': 714, 'perform': 715, 'manipulation': 716, 'navigation': 717, 'fraudulent': 718, 'activity': 719, 'system': 720, 'failures': 721, 'descriptive': 722, 'combining': 723, 'vehicles': 724, 'robotic': 725, 'robots': 726, 'surroundings': 727, 'distribution': 728, 'existing': 729, 'particularly': 730, 'diverse': 731, 'biology': 732, 'marketing': 733, 'computationally': 734, 'ethics': 735, 'consideration': 736, 'deploying': 737, 'sensitive': 738, 'law': 739, 'enforcement': 740, 'unfair': 741, 'necessitating': 742, 'careful': 743, 'safety': 744, 'act': 745, 'alignment': 746, 'priorities': 747, 'governance': 748, 'establishing': 749, 'policies': 750, 'guidelines': 751, 'responsible': 752, 'simplify': 753, 'creation': 754, 'enabled': 755, 'major': 756, 'imaging': 757, 'x': 758, 'rays': 759, 'mris': 760, 'diseases': 761, 'cancer': 762, 'navigate': 763, 'autonomously': 764, 'integral': 765, 'productivity': 766, 'experience': 767, 'continuously': 768, 'evolving': 769, 'researchers': 770, 'exploring': 771, 'removing': 772, 'unnecessary': 773, 'floating': 774, 'point': 775, 'numbers': 776, 'lower': 777, 'formats': 778, 'usage': 779, 'costs': 780, 'test': 781, 'prevention': 782, 'balance': 783, 'complexity': 784, \"haven't\": 785, 'prior': 786, 'holds': 787, 'immense': 788, 'solving': 789, 'climate': 790, 'science': 791, 'space': 792, 'exploration': 793, 'here': 794, 'list': 795, 'about': 796, 'equal': 797, 'conv': 798, 'slides': 799, 'stride': 800, 'defines': 801, 'moves': 802, 'padding': 803, 'extra': 804, 'pixels': 805, 'around': 806, 'selects': 807, 'maximum': 808, 'takes': 809, 'fc': 810, 'connects': 811, 'every': 812, 'neuron': 813, 'normalizes': 814, 'stability': 815, 'averaging': 816, 'entire': 817, 'stages': 818, 'spaced': 819, 'out': 820, 'filters': 821, 'larger': 822, '1x1': 823, 'transposed': 824, 'deconvolutions': 825, 'upsample': 826, 'apply': 827, 'separate': 828, 'width': 829, 'height': 830, 'bypass': 831, 'inception': 832, 'scales': 833, 'first': 834, 'vggnet': 835, 'smaller': 836, '3x3': 837, 'lenet': 838, 'handwritten': 839, 'digit': 840, 'squeezenet': 841, 'number': 842, 'mobilenet': 843, 'optimized': 844, 'mobile': 845, 'operations': 846, 'densenet': 847, 'dense': 848, 'reuse': 849, 'flow': 850, 'xception': 851, 'u': 852, 'net': 853, 'symmetric': 854, 'r': 855, 'proposal': 856, 'rpn': 857, 'yolo': 858, 'only': 859, 'look': 860, 'directly': 861, 'ssd': 862, 'multibox': 863, 'detector': 864, 'fpn': 865, 'top': 866, 'down': 867, 'states': 868, 'timesteps': 869, 'crnn': 870, 'summarizes': 871, '1d': 872, '3d': 873, 'extends': 874, 'three': 875, 'commonly': 876, 'regions': 877, 'resnext': 878, 'split': 879, 'transform': 880, 'merge': 881, 'strategy': 882, 'styles': 883, 'onto': 884, 'handles': 885, 'resizing': 886, 'receptive': 887, 'low': 888, '50': 889, 'lightweight': 890, 'variants': 891, 'introduced': 892, 'represent': 893, 'after': 894, 'standardizes': 895, 'stable': 896, 'fraction': 897, 'units': 898, 'downsample': 899, 'comes': 900, 'end': 901, 'remembers': 902, 'embedding': 903, 'backward': 904, 'scenes': 905, 'class': 906, 'finds': 907, 'category': 908, 'face': 909, 'instance': 910, 'interest': 911, 'classify': 912, 'abnormal': 913, 'simplified': 914, 'gating': 915, 'mitigating': 916, 'limits': 917, 'audio': 918, 'signals': 919, 'learned': 920, 'lengths': 921, 'han': 922, 'document': 923, 'determine': 924, 'essential': 925, 'translates': 926, 'languages': 927, 'structures': 928, 'textual': 929, 'descriptions': 930, 'sequentially': 931, 'summarization': 932, 'named': 933, 'entity': 934, 'entities': 935, 'names': 936, 'dates': 937, 'reverse': 938, 'involve': 939, 'tcn': 940, 'replace': 941, 'explicitly': 942, 'programmed': 943, 'association': 944, 'trains': 945, 'trial': 946, 'maximize': 947, 'dynamic': 948, 'quality': 949, 'quantity': 950, 'plays': 951, 'role': 952, 'determining': 953, 'aspects': 954, 'valuable': 955, 'losing': 956, 'underfitting': 957, 'happens': 958, 'fails': 959, 'underlying': 960, \"model's\": 961, 'splitting': 962, 'subsets': 963, 'linear': 964, 'regression': 965, 'trees': 966, 'forests': 967, 'branch': 968, 'focused': 969, 'recommendation': 970, 'netflix': 971, 'amazon': 972, 'suggesting': 973, 'behavior': 974, 'key': 975, 'application': 976, 'visual': 977, 'concerns': 978, 'algorithmic': 979, 'misuse': 980, 'surveillance': 981, 'explainability': 982, 'deployed': 983, 'cloud': 984, 'scalability': 985, 'access': 986, 'powerful': 987, 'optimizes': 988, 'successful': 989, 'gaming': 990, 'revolutionizing': 991, 'automation': 992, 'analytics': 993, 'handling': 994, 'missing': 995, 'vital': 996, 'biased': 997, 'potentially': 998, 'reinforcing': 999, 'stereotypes': 1000, 'practices': 1001, 'intrusions': 1002, 'widely': 1003, 'technique': 1004, 'boosting': 1005, 'bagging': 1006, 'enhance': 1007, 'k': 1008, 'means': 1009, 'group': 1010, 'market': 1011, 'trends': 1012, 'nodes': 1013, 'mimic': 1014, 'continuous': 1015, 'monitoring': 1016, 'remain': 1017, 'accurate': 1018, 'arrives': 1019, 'depends': 1020, 'semi': 1021, 'spot': 1022, 'outliers': 1023, 'cyberattacks': 1024, 'equipment': 1025, 'malfunctions': 1026, 'iterative': 1027, 'refinement': 1028, 'evaluation': 1029, 'prone': 1030, 'attacks': 1031, 'small': 1032, 'changes': 1033, 'mislead': 1034, 'attributes': 1035, 'tools': 1036, 'automate': 1037, 'experts': 1038, 'tune': 1039, 'active': 1040, 'feedback': 1041, 'scarce': 1042, 'resemble': 1043, 'distributed': 1044, 'industry': 1045, 'personalized': 1046, 'treatment': 1047, 'plans': 1048, 'fair': 1049, 'transparent': 1050, 'accountable': 1051, 'powered': 1052, 'chatbots': 1053, 'engage': 1054, 'conversations': 1055, 'customer': 1056, 'responses': 1057, 'continually': 1058, 'research': 1059, 'matures': 1060, 'promises': 1061, 'drive': 1062, 'innovation': 1063, 'sectors': 1064, 'creativity': 1065, 'capabilities': 1066}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "for sen in data.split('\\n'):\n",
        "   tok_sen = tokenizer.texts_to_sequences([sen])[0]\n",
        "   for i in range(1, len(tok_sen)):\n",
        "    arr.append(tok_sen[:i+1])\n"
      ],
      "metadata": {
        "id": "9W5g7af60Vgz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ID7PplCWvtxb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F25D4dH40mWB",
        "outputId": "27a86b38-ff09-4cd6-e79f-142c1d08745c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 4],\n",
              " [9, 4, 14],\n",
              " [9, 4, 14, 12],\n",
              " [9, 4, 14, 12, 233],\n",
              " [9, 4, 14, 12, 233, 8],\n",
              " [9, 4, 14, 12, 233, 8, 70],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3, 181],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3, 181, 1],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3, 181, 1, 182],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3, 181, 1, 182, 8],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3, 181, 1, 182, 8, 3],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3, 181, 1, 182, 8, 3, 336],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3, 181, 1, 182, 8, 3, 336, 528],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 234, 15, 3, 181, 1, 182, 8, 3, 336, 528, 235],\n",
              " [9,\n",
              "  4,\n",
              "  14,\n",
              "  12,\n",
              "  233,\n",
              "  8,\n",
              "  70,\n",
              "  4,\n",
              "  234,\n",
              "  15,\n",
              "  3,\n",
              "  181,\n",
              "  1,\n",
              "  182,\n",
              "  8,\n",
              "  3,\n",
              "  336,\n",
              "  528,\n",
              "  235,\n",
              "  30],\n",
              " [9,\n",
              "  4,\n",
              "  14,\n",
              "  12,\n",
              "  233,\n",
              "  8,\n",
              "  70,\n",
              "  4,\n",
              "  234,\n",
              "  15,\n",
              "  3,\n",
              "  181,\n",
              "  1,\n",
              "  182,\n",
              "  8,\n",
              "  3,\n",
              "  336,\n",
              "  528,\n",
              "  235,\n",
              "  30,\n",
              "  16],\n",
              " [119, 120],\n",
              " [119, 120, 17],\n",
              " [119, 120, 17, 10],\n",
              " [119, 120, 17, 10, 20],\n",
              " [119, 120, 17, 10, 20, 51],\n",
              " [119, 120, 17, 10, 20, 51, 27],\n",
              " [119, 120, 17, 10, 20, 51, 27, 8],\n",
              " [119, 120, 17, 10, 20, 51, 27, 8, 97],\n",
              " [119, 120, 17, 10, 20, 51, 27, 8, 97, 529],\n",
              " [119, 120, 17, 10, 20, 51, 27, 8, 97, 529, 9],\n",
              " [119, 120, 17, 10, 20, 51, 27, 8, 97, 529, 9, 16],\n",
              " [97, 7],\n",
              " [97, 7, 9],\n",
              " [97, 7, 9, 4],\n",
              " [97, 7, 9, 4, 18],\n",
              " [97, 7, 9, 4, 18, 530],\n",
              " [97, 7, 9, 4, 18, 530, 150],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61, 236],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61, 236, 1],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61, 236, 1, 531],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61, 236, 1, 531, 13],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61, 236, 1, 531, 13, 237],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61, 236, 1, 531, 13, 237, 2],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61, 236, 1, 531, 13, 237, 2, 532],\n",
              " [97, 7, 9, 4, 18, 530, 150, 34, 61, 236, 1, 531, 13, 237, 2, 532, 27],\n",
              " [38, 31],\n",
              " [38, 31, 7],\n",
              " [38, 31, 7, 12],\n",
              " [38, 31, 7, 12, 9],\n",
              " [38, 31, 7, 12, 9, 62],\n",
              " [38, 31, 7, 12, 9, 62, 238],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239, 28],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239, 28, 45],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239, 28, 45, 337],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239, 28, 45, 337, 240],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239, 28, 45, 337, 240, 7],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239, 28, 45, 337, 240, 7, 48],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239, 28, 45, 337, 240, 7, 48, 2],\n",
              " [38, 31, 7, 12, 9, 62, 238, 12, 533, 239, 28, 45, 337, 240, 7, 48, 2, 39],\n",
              " [38,\n",
              "  31,\n",
              "  7,\n",
              "  12,\n",
              "  9,\n",
              "  62,\n",
              "  238,\n",
              "  12,\n",
              "  533,\n",
              "  239,\n",
              "  28,\n",
              "  45,\n",
              "  337,\n",
              "  240,\n",
              "  7,\n",
              "  48,\n",
              "  2,\n",
              "  39,\n",
              "  338],\n",
              " [38,\n",
              "  31,\n",
              "  7,\n",
              "  12,\n",
              "  9,\n",
              "  62,\n",
              "  238,\n",
              "  12,\n",
              "  533,\n",
              "  239,\n",
              "  28,\n",
              "  45,\n",
              "  337,\n",
              "  240,\n",
              "  7,\n",
              "  48,\n",
              "  2,\n",
              "  39,\n",
              "  338,\n",
              "  23],\n",
              " [38,\n",
              "  31,\n",
              "  7,\n",
              "  12,\n",
              "  9,\n",
              "  62,\n",
              "  238,\n",
              "  12,\n",
              "  533,\n",
              "  239,\n",
              "  28,\n",
              "  45,\n",
              "  337,\n",
              "  240,\n",
              "  7,\n",
              "  48,\n",
              "  2,\n",
              "  39,\n",
              "  338,\n",
              "  23,\n",
              "  80],\n",
              " [151, 150],\n",
              " [151, 150, 11],\n",
              " [151, 150, 11, 241],\n",
              " [151, 150, 11, 241, 1],\n",
              " [151, 150, 11, 241, 1, 339],\n",
              " [151, 150, 11, 241, 1, 339, 63],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340, 183],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340, 183, 242],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340, 183, 242, 98],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340, 183, 242, 98, 16],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340, 183, 242, 98, 16, 2],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340, 183, 242, 98, 16, 2, 152],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340, 183, 242, 98, 16, 2, 152, 39],\n",
              " [151, 150, 11, 241, 1, 339, 63, 340, 183, 242, 98, 16, 2, 152, 39, 153],\n",
              " [341, 14],\n",
              " [341, 14, 3],\n",
              " [341, 14, 3, 61],\n",
              " [341, 14, 3, 61, 154],\n",
              " [341, 14, 3, 61, 154, 184],\n",
              " [341, 14, 3, 61, 154, 184, 9],\n",
              " [341, 14, 3, 61, 154, 184, 9, 16],\n",
              " [341, 14, 3, 61, 154, 184, 9, 16, 342],\n",
              " [341, 14, 3, 61, 154, 184, 9, 16, 342, 121],\n",
              " [341, 14, 3, 61, 154, 184, 9, 16, 342, 121, 40],\n",
              " [341, 14, 3, 61, 154, 184, 9, 16, 342, 121, 40, 13],\n",
              " [341, 14, 3, 61, 154, 184, 9, 16, 342, 121, 40, 13, 185],\n",
              " [341, 14, 3, 61, 154, 184, 9, 16, 342, 121, 40, 13, 185, 343],\n",
              " [341, 14, 3, 61, 154, 184, 9, 16, 342, 121, 40, 13, 185, 343, 25],\n",
              " [243, 344],\n",
              " [243, 344, 244],\n",
              " [243, 344, 244, 81],\n",
              " [243, 344, 244, 81, 30],\n",
              " [243, 344, 244, 81, 30, 16],\n",
              " [243, 344, 244, 81, 30, 16, 52],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5, 1],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5, 1, 99],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5, 1, 99, 30],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5, 1, 99, 30, 16],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5, 1, 99, 30, 16, 41],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5, 1, 99, 30, 16, 41, 6],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5, 1, 99, 30, 16, 41, 6, 71],\n",
              " [243, 344, 244, 81, 30, 16, 52, 6, 24, 5, 1, 99, 30, 16, 41, 6, 71, 5],\n",
              " [9, 4],\n",
              " [9, 4, 534],\n",
              " [9, 4, 534, 7],\n",
              " [9, 4, 534, 7, 245],\n",
              " [9, 4, 534, 7, 245, 155],\n",
              " [9, 4, 534, 7, 245, 155, 246],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122, 82],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122, 82, 53],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122, 82, 53, 123],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122, 82, 53, 123, 100],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122, 82, 53, 123, 100, 72],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122, 82, 53, 123, 100, 72, 54],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122, 82, 53, 123, 100, 72, 54, 1],\n",
              " [9, 4, 534, 7, 245, 155, 246, 535, 5, 122, 82, 53, 123, 100, 72, 54, 1, 101],\n",
              " [17, 9],\n",
              " [17, 9, 16],\n",
              " [17, 9, 16, 186],\n",
              " [17, 9, 16, 186, 187],\n",
              " [17, 9, 16, 186, 187, 83],\n",
              " [17, 9, 16, 186, 187, 83, 102],\n",
              " [17, 9, 16, 186, 187, 83, 102, 1],\n",
              " [17, 9, 16, 186, 187, 83, 102, 1, 247],\n",
              " [17, 9, 16, 186, 187, 83, 102, 1, 247, 103],\n",
              " [17, 9, 16, 186, 187, 83, 102, 1, 247, 103, 156],\n",
              " [55, 14],\n",
              " [55, 14, 12],\n",
              " [55, 14, 12, 243],\n",
              " [55, 14, 12, 243, 536],\n",
              " [55, 14, 12, 243, 536, 157],\n",
              " [55, 14, 12, 243, 536, 157, 3],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124, 13],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124, 13, 17],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124, 13, 17, 5],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124, 13, 17, 5, 345],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124, 13, 17, 5, 345, 346],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124, 13, 17, 5, 345, 346, 13],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124, 13, 17, 5, 345, 346, 13, 64],\n",
              " [55, 14, 12, 243, 536, 157, 3, 21, 537, 124, 13, 17, 5, 345, 346, 13, 64, 5],\n",
              " [248, 65],\n",
              " [248, 65, 11],\n",
              " [248, 65, 11, 125],\n",
              " [248, 65, 11, 125, 1],\n",
              " [248, 65, 11, 125, 1, 249],\n",
              " [248, 65, 11, 125, 1, 249, 538],\n",
              " [248, 65, 11, 125, 1, 249, 538, 63],\n",
              " [248, 65, 11, 125, 1, 249, 538, 63, 2],\n",
              " [248, 65, 11, 125, 1, 249, 538, 63, 2, 539],\n",
              " [248, 65, 11, 125, 1, 249, 538, 63, 2, 539, 55],\n",
              " [73, 4],\n",
              " [73, 4, 158],\n",
              " [73, 4, 158, 10],\n",
              " [73, 4, 158, 10, 159],\n",
              " [73, 4, 158, 10, 159, 13],\n",
              " [73, 4, 158, 10, 159, 13, 104],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56, 188],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56, 188, 250],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56, 188, 250, 6],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56, 188, 250, 6, 127],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56, 188, 250, 6, 127, 251],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56, 188, 250, 6, 127, 251, 3],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56, 188, 250, 6, 127, 251, 3, 540],\n",
              " [73, 4, 158, 10, 159, 13, 104, 126, 2, 56, 188, 250, 6, 127, 251, 3, 540, 6],\n",
              " [73,\n",
              "  4,\n",
              "  158,\n",
              "  10,\n",
              "  159,\n",
              "  13,\n",
              "  104,\n",
              "  126,\n",
              "  2,\n",
              "  56,\n",
              "  188,\n",
              "  250,\n",
              "  6,\n",
              "  127,\n",
              "  251,\n",
              "  3,\n",
              "  540,\n",
              "  6,\n",
              "  347],\n",
              " [73,\n",
              "  4,\n",
              "  158,\n",
              "  10,\n",
              "  159,\n",
              "  13,\n",
              "  104,\n",
              "  126,\n",
              "  2,\n",
              "  56,\n",
              "  188,\n",
              "  250,\n",
              "  6,\n",
              "  127,\n",
              "  251,\n",
              "  3,\n",
              "  540,\n",
              "  6,\n",
              "  347,\n",
              "  5],\n",
              " [348, 18],\n",
              " [348, 18, 29],\n",
              " [348, 18, 29, 7],\n",
              " [348, 18, 29, 7, 9],\n",
              " [348, 18, 29, 7, 9, 4],\n",
              " [348, 18, 29, 7, 9, 4, 6],\n",
              " [348, 18, 29, 7, 9, 4, 6, 189],\n",
              " [348, 18, 29, 7, 9, 4, 6, 189, 19],\n",
              " [348, 18, 29, 7, 9, 4, 6, 189, 19, 11],\n",
              " [348, 18, 29, 7, 9, 4, 6, 189, 19, 11, 252],\n",
              " [348, 18, 29, 7, 9, 4, 6, 189, 19, 11, 252, 253],\n",
              " [348, 18, 29, 7, 9, 4, 6, 189, 19, 11, 252, 253, 1],\n",
              " [348, 18, 29, 7, 9, 4, 6, 189, 19, 11, 252, 253, 1, 128],\n",
              " [348, 18, 29, 7, 9, 4, 6, 189, 19, 11, 252, 253, 1, 128, 42],\n",
              " [190, 254],\n",
              " [190, 254, 16],\n",
              " [190, 254, 16, 160],\n",
              " [190, 254, 16, 160, 18],\n",
              " [190, 254, 16, 160, 18, 12],\n",
              " [190, 254, 16, 160, 18, 12, 191],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4, 21],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4, 21, 29],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4, 21, 29, 2],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4, 21, 29, 2, 349],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4, 21, 29, 2, 349, 64],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4, 21, 29, 2, 349, 64, 350],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4, 21, 29, 2, 349, 64, 350, 5],\n",
              " [190, 254, 16, 160, 18, 12, 191, 8, 9, 4, 21, 29, 2, 349, 64, 350, 5, 541],\n",
              " [9, 66],\n",
              " [9, 66, 4],\n",
              " [9, 66, 4, 105],\n",
              " [9, 66, 4, 105, 9],\n",
              " [9, 66, 4, 105, 9, 4],\n",
              " [9, 66, 4, 105, 9, 4, 20],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 98],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 98, 129],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 98, 129, 2],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 98, 129, 2, 84],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 98, 129, 2, 84, 39],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 98, 129, 2, 84, 39, 19],\n",
              " [351, 11],\n",
              " [351, 11, 255],\n",
              " [351, 11, 255, 1],\n",
              " [351, 11, 255, 1, 256],\n",
              " [351, 11, 255, 1, 256, 352],\n",
              " [351, 11, 255, 1, 256, 352, 106],\n",
              " [351, 11, 255, 1, 256, 352, 106, 192],\n",
              " [351, 11, 255, 1, 256, 352, 106, 192, 18],\n",
              " [351, 11, 255, 1, 256, 352, 106, 192, 18, 257],\n",
              " [351, 11, 255, 1, 256, 352, 106, 192, 18, 257, 6],\n",
              " [351, 11, 255, 1, 256, 352, 106, 192, 18, 257, 6, 193],\n",
              " [351, 11, 255, 1, 256, 352, 106, 192, 18, 257, 6, 193, 17],\n",
              " [351, 11, 255, 1, 256, 352, 106, 192, 18, 257, 6, 193, 17, 9],\n",
              " [351, 11, 255, 1, 256, 352, 106, 192, 18, 257, 6, 193, 17, 9, 10],\n",
              " [9, 4],\n",
              " [9, 4, 14],\n",
              " [9, 4, 14, 5],\n",
              " [9, 4, 14, 5, 353],\n",
              " [9, 4, 14, 5, 353, 155],\n",
              " [9, 4, 14, 5, 353, 155, 347],\n",
              " [9, 4, 14, 5, 353, 155, 347, 161],\n",
              " [9, 4, 14, 5, 353, 155, 347, 161, 5],\n",
              " [9, 4, 14, 5, 353, 155, 347, 161, 5, 2],\n",
              " [9, 4, 14, 5, 353, 155, 347, 161, 5, 2, 130],\n",
              " [9, 4, 14, 5, 353, 155, 347, 161, 5, 2, 130, 542],\n",
              " [3, 354],\n",
              " [3, 354, 194],\n",
              " [3, 354, 194, 195],\n",
              " [3, 354, 194, 195, 196],\n",
              " [3, 354, 194, 195, 196, 1],\n",
              " [3, 354, 194, 195, 196, 1, 355],\n",
              " [3, 354, 194, 195, 196, 1, 355, 131],\n",
              " [3, 354, 194, 195, 196, 1, 355, 131, 356],\n",
              " [3, 354, 194, 195, 196, 1, 355, 131, 356, 357],\n",
              " [3, 354, 194, 195, 196, 1, 355, 131, 356, 357, 6],\n",
              " [3, 354, 194, 195, 196, 1, 355, 131, 356, 357, 6, 9],\n",
              " [3, 354, 194, 195, 196, 1, 355, 131, 356, 357, 6, 9, 543],\n",
              " [3, 354, 194, 195, 196, 1, 355, 131, 356, 357, 6, 9, 543, 544],\n",
              " [358, 11],\n",
              " [358, 11, 545],\n",
              " [358, 11, 545, 546],\n",
              " [358, 11, 545, 546, 1],\n",
              " [358, 11, 545, 546, 1, 547],\n",
              " [358, 11, 545, 546, 1, 547, 131],\n",
              " [358, 11, 545, 546, 1, 547, 131, 548],\n",
              " [358, 11, 545, 546, 1, 547, 131, 548, 9],\n",
              " [358, 11, 545, 546, 1, 547, 131, 548, 9, 4],\n",
              " [358, 11, 545, 546, 1, 547, 131, 548, 9, 4, 359],\n",
              " [358, 11, 545, 546, 1, 547, 131, 548, 9, 4, 359, 1],\n",
              " [358, 11, 545, 546, 1, 547, 131, 548, 9, 4, 359, 1, 549],\n",
              " [9, 4],\n",
              " [9, 4, 550],\n",
              " [9, 4, 550, 2],\n",
              " [9, 4, 550, 2, 360],\n",
              " [9, 4, 550, 2, 360, 551],\n",
              " [9, 4, 550, 2, 360, 551, 3],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7, 74],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7, 74, 162],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7, 74, 162, 85],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7, 74, 162, 85, 258],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7, 74, 162, 85, 258, 45],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7, 74, 162, 85, 258, 45, 132],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7, 74, 162, 85, 258, 45, 132, 2],\n",
              " [9, 4, 550, 2, 360, 551, 3, 552, 7, 74, 162, 85, 258, 45, 132, 2, 361],\n",
              " [362, 553],\n",
              " [362, 553, 12],\n",
              " [362, 553, 12, 363],\n",
              " [362, 553, 12, 363, 554],\n",
              " [362, 553, 12, 363, 554, 8],\n",
              " [362, 553, 12, 363, 554, 8, 9],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4, 7],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4, 7, 364],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4, 7, 364, 38],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4, 7, 364, 38, 365],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4, 7, 364, 38, 365, 555],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4, 7, 364, 38, 365, 555, 197],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4, 7, 364, 38, 365, 555, 197, 23],\n",
              " [362, 553, 12, 363, 554, 8, 9, 4, 7, 364, 38, 365, 555, 197, 23, 86],\n",
              " [9, 4],\n",
              " [9, 4, 14],\n",
              " [9, 4, 14, 12],\n",
              " [9, 4, 14, 12, 233],\n",
              " [9, 4, 14, 12, 233, 8],\n",
              " [9, 4, 14, 12, 233, 8, 70],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 34],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 34, 556],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 34, 556, 3],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 34, 556, 3, 107],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 34, 556, 3, 107, 557],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 34, 556, 3, 107, 557, 181],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 34, 556, 3, 107, 557, 181, 1],\n",
              " [9, 4, 14, 12, 233, 8, 70, 4, 34, 556, 3, 107, 557, 181, 1, 182],\n",
              " [119, 35],\n",
              " [119, 35, 235],\n",
              " [119, 35, 235, 30],\n",
              " [119, 35, 235, 30, 16],\n",
              " [119, 35, 235, 30, 16, 558],\n",
              " [119, 35, 235, 30, 16, 558, 20],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27, 2],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27, 2, 61],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27, 2, 61, 5],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27, 2, 61, 5, 1],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27, 2, 61, 5, 1, 108],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27, 2, 61, 5, 1, 108, 163],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27, 2, 61, 5, 1, 108, 163, 23],\n",
              " [119, 35, 235, 30, 16, 558, 20, 51, 27, 2, 61, 5, 1, 108, 163, 23, 559],\n",
              " [9, 4],\n",
              " [9, 4, 10],\n",
              " [9, 4, 10, 84],\n",
              " [9, 4, 10, 84, 45],\n",
              " [9, 4, 10, 84, 45, 83],\n",
              " [9, 4, 10, 84, 45, 83, 102],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46, 34],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46, 34, 561],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46, 34, 561, 56],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46, 34, 561, 56, 562],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46, 34, 561, 56, 562, 6],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46, 34, 561, 56, 562, 6, 259],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46, 34, 561, 56, 562, 6, 259, 70],\n",
              " [9, 4, 10, 84, 45, 83, 102, 560, 46, 34, 561, 56, 562, 6, 259, 70, 4],\n",
              " [3, 366],\n",
              " [3, 366, 563],\n",
              " [3, 366, 563, 14],\n",
              " [3, 366, 563, 14, 2],\n",
              " [3, 366, 563, 14, 2, 367],\n",
              " [3, 366, 563, 14, 2, 367, 368],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564, 47],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564, 47, 109],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564, 47, 109, 25],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564, 47, 109, 25, 154],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564, 47, 109, 25, 154, 565],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564, 47, 109, 25, 154, 565, 2],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564, 47, 109, 25, 154, 565, 2, 75],\n",
              " [3, 366, 563, 14, 2, 367, 368, 2, 564, 47, 109, 25, 154, 565, 2, 75, 5],\n",
              " [30, 16],\n",
              " [30, 16, 369],\n",
              " [30, 16, 369, 8],\n",
              " [30, 16, 369, 8, 36],\n",
              " [30, 16, 369, 8, 36, 198],\n",
              " [30, 16, 369, 8, 36, 198, 1],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27, 20],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27, 20, 38],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27, 20, 38, 31],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27, 20, 38, 31, 566],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27, 20, 38, 31, 566, 260],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27, 20, 38, 31, 566, 260, 567],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27, 20, 38, 31, 566, 260, 567, 8],\n",
              " [30, 16, 369, 8, 36, 198, 1, 133, 27, 20, 38, 31, 566, 260, 567, 8, 568],\n",
              " [3, 36],\n",
              " [3, 36, 31],\n",
              " [3, 36, 31, 569],\n",
              " [3, 36, 31, 569, 370],\n",
              " [3, 36, 31, 569, 370, 5],\n",
              " [3, 36, 31, 569, 370, 5, 184],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154, 198],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154, 198, 27],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154, 198, 27, 6],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154, 198, 27, 6, 49],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154, 198, 27, 6, 49, 1],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154, 198, 27, 6, 49, 1, 3],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154, 198, 27, 6, 49, 1, 3, 133],\n",
              " [3, 36, 31, 569, 370, 5, 184, 14, 570, 154, 198, 27, 6, 49, 1, 3, 133, 31],\n",
              " [3,\n",
              "  36,\n",
              "  31,\n",
              "  569,\n",
              "  370,\n",
              "  5,\n",
              "  184,\n",
              "  14,\n",
              "  570,\n",
              "  154,\n",
              "  198,\n",
              "  27,\n",
              "  6,\n",
              "  49,\n",
              "  1,\n",
              "  3,\n",
              "  133,\n",
              "  31,\n",
              "  371],\n",
              " [3,\n",
              "  36,\n",
              "  31,\n",
              "  569,\n",
              "  370,\n",
              "  5,\n",
              "  184,\n",
              "  14,\n",
              "  570,\n",
              "  154,\n",
              "  198,\n",
              "  27,\n",
              "  6,\n",
              "  49,\n",
              "  1,\n",
              "  3,\n",
              "  133,\n",
              "  31,\n",
              "  371,\n",
              "  163],\n",
              " [151, 150],\n",
              " [151, 150, 11],\n",
              " [151, 150, 11, 241],\n",
              " [151, 150, 11, 241, 1],\n",
              " [151, 150, 11, 241, 1, 339],\n",
              " [151, 150, 11, 241, 1, 339, 340],\n",
              " [151, 150, 11, 241, 1, 339, 340, 183],\n",
              " [151, 150, 11, 241, 1, 339, 340, 183, 242],\n",
              " [151, 150, 11, 241, 1, 339, 340, 183, 242, 261],\n",
              " [151, 150, 11, 241, 1, 339, 340, 183, 242, 261, 16],\n",
              " [151, 150, 11, 241, 1, 339, 340, 183, 242, 261, 16, 2],\n",
              " [151, 150, 11, 241, 1, 339, 340, 183, 242, 261, 16, 2, 152],\n",
              " [151, 150, 11, 241, 1, 339, 340, 183, 242, 261, 16, 2, 152, 39],\n",
              " [151, 150, 11, 241, 1, 339, 340, 183, 242, 261, 16, 2, 152, 39, 153],\n",
              " [341, 571],\n",
              " [341, 571, 121],\n",
              " [341, 571, 121, 7],\n",
              " [341, 571, 121, 7, 3],\n",
              " [341, 571, 121, 7, 3, 62],\n",
              " [341, 571, 121, 7, 3, 62, 15],\n",
              " [341, 571, 121, 7, 3, 62, 15, 372],\n",
              " [341, 571, 121, 7, 3, 62, 15, 372, 3],\n",
              " [341, 571, 121, 7, 3, 62, 15, 372, 3, 262],\n",
              " [341, 571, 121, 7, 3, 62, 15, 372, 3, 262, 134],\n",
              " [341, 571, 121, 7, 3, 62, 15, 372, 3, 262, 134, 373],\n",
              " [341, 571, 121, 7, 3, 62, 15, 372, 3, 262, 134, 373, 1],\n",
              " [341, 571, 121, 7, 3, 62, 15, 372, 3, 262, 134, 373, 1, 374],\n",
              " [341, 571, 121, 7, 3, 62, 15, 372, 3, 262, 134, 373, 1, 374, 375],\n",
              " [106, 192],\n",
              " [106, 192, 14],\n",
              " [106, 192, 14, 29],\n",
              " [106, 192, 14, 29, 2],\n",
              " [106, 192, 14, 29, 2, 263],\n",
              " [106, 192, 14, 29, 2, 263, 3],\n",
              " [106, 192, 14, 29, 2, 263, 3, 376],\n",
              " [106, 192, 14, 29, 2, 263, 3, 376, 182],\n",
              " [106, 192, 14, 29, 2, 263, 3, 376, 182, 15],\n",
              " [106, 192, 14, 29, 2, 263, 3, 376, 182, 15, 572],\n",
              " [106, 192, 14, 29, 2, 263, 3, 376, 182, 15, 572, 21],\n",
              " [106, 192, 14, 29, 2, 263, 3, 376, 182, 15, 572, 21, 76],\n",
              " [106, 192, 14, 29, 2, 263, 3, 376, 182, 15, 572, 21, 76, 573],\n",
              " [9, 4],\n",
              " [9, 4, 574],\n",
              " [9, 4, 574, 13],\n",
              " [9, 4, 574, 13, 575],\n",
              " [9, 4, 574, 13, 575, 5],\n",
              " [9, 4, 574, 13, 575, 5, 157],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75, 5],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75, 5, 377],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75, 5, 377, 576],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75, 5, 377, 576, 3],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75, 5, 377, 576, 3, 135],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75, 5, 377, 576, 3, 135, 3],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75, 5, 377, 576, 3, 135, 3, 264],\n",
              " [9, 4, 574, 13, 575, 5, 157, 3, 75, 5, 377, 576, 3, 135, 3, 264, 25],\n",
              " [12, 81],\n",
              " [12, 81, 30],\n",
              " [12, 81, 30, 62],\n",
              " [12, 81, 30, 62, 43],\n",
              " [12, 81, 30, 62, 43, 14],\n",
              " [12, 81, 30, 62, 43, 14, 265],\n",
              " [12, 81, 30, 62, 43, 14, 265, 6],\n",
              " [12, 81, 30, 62, 43, 14, 265, 6, 49],\n",
              " [12, 81, 30, 62, 43, 14, 265, 6, 49, 24],\n",
              " [12, 81, 30, 62, 43, 14, 265, 6, 49, 24, 5],\n",
              " [12, 81, 30, 62, 43, 14, 265, 6, 49, 24, 5, 1],\n",
              " [12, 81, 30, 62, 43, 14, 265, 6, 49, 24, 5, 1, 378],\n",
              " [12, 81, 30, 62, 43, 14, 265, 6, 49, 24, 5, 1, 378, 136],\n",
              " [12, 81, 30, 62, 43, 14, 265, 6, 49, 24, 5, 1, 378, 136, 577],\n",
              " [52, 50],\n",
              " [52, 50, 81],\n",
              " [52, 50, 81, 27],\n",
              " [52, 50, 81, 27, 2],\n",
              " [52, 50, 81, 27, 2, 266],\n",
              " [52, 50, 81, 27, 2, 266, 46],\n",
              " [52, 50, 81, 27, 2, 266, 46, 7],\n",
              " [52, 50, 81, 27, 2, 266, 46, 7, 48],\n",
              " [52, 50, 81, 27, 2, 266, 46, 7, 48, 82],\n",
              " [52, 50, 81, 27, 2, 266, 46, 7, 48, 82, 53],\n",
              " [52, 50, 81, 27, 2, 266, 46, 7, 48, 82, 53, 240],\n",
              " [52, 50, 81, 27, 2, 266, 46, 7, 48, 82, 53, 240, 338],\n",
              " [52, 50, 81, 27, 2, 266, 46, 7, 48, 82, 53, 240, 338, 1],\n",
              " [52, 50, 81, 27, 2, 266, 46, 7, 48, 82, 53, 240, 338, 1, 379],\n",
              " [99, 30],\n",
              " [99, 30, 16],\n",
              " [99, 30, 16, 41],\n",
              " [99, 30, 16, 41, 18],\n",
              " [99, 30, 16, 41, 18, 380],\n",
              " [99, 30, 16, 41, 18, 380, 6],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5, 11],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5, 11, 32],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5, 11, 32, 87],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5, 11, 32, 87, 23],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5, 11, 32, 87, 23, 137],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5, 11, 32, 87, 23, 137, 44],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5, 11, 32, 87, 23, 137, 44, 49],\n",
              " [99, 30, 16, 41, 18, 380, 6, 71, 5, 11, 32, 87, 23, 137, 44, 49, 101],\n",
              " [41, 131],\n",
              " [41, 131, 578],\n",
              " [41, 131, 578, 34],\n",
              " [41, 131, 578, 34, 267],\n",
              " [41, 131, 578, 34, 267, 164],\n",
              " [41, 131, 578, 34, 267, 164, 2],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85, 57],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85, 57, 110],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85, 57, 110, 165],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85, 57, 110, 165, 381],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85, 57, 110, 165, 381, 6],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85, 57, 110, 165, 381, 6, 19],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85, 57, 110, 165, 381, 6, 19, 11],\n",
              " [41, 131, 578, 34, 267, 164, 2, 579, 85, 57, 110, 165, 381, 6, 19, 11, 72],\n",
              " [41,\n",
              "  131,\n",
              "  578,\n",
              "  34,\n",
              "  267,\n",
              "  164,\n",
              "  2,\n",
              "  579,\n",
              "  85,\n",
              "  57,\n",
              "  110,\n",
              "  165,\n",
              "  381,\n",
              "  6,\n",
              "  19,\n",
              "  11,\n",
              "  72,\n",
              "  54],\n",
              " [67, 199],\n",
              " [67, 199, 77],\n",
              " [67, 199, 77, 88],\n",
              " [67, 199, 77, 88, 58],\n",
              " [67, 199, 77, 88, 58, 14],\n",
              " [67, 199, 77, 88, 58, 14, 12],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26, 34],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26, 34, 580],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26, 34, 580, 3],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26, 34, 580, 3, 200],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26, 34, 580, 3, 200, 106],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26, 34, 580, 3, 200, 106, 268],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26, 34, 580, 3, 200, 106, 268, 7],\n",
              " [67, 199, 77, 88, 58, 14, 12, 191, 8, 26, 34, 580, 3, 200, 106, 268, 7, 67],\n",
              " [67,\n",
              "  199,\n",
              "  77,\n",
              "  88,\n",
              "  58,\n",
              "  14,\n",
              "  12,\n",
              "  191,\n",
              "  8,\n",
              "  26,\n",
              "  34,\n",
              "  580,\n",
              "  3,\n",
              "  200,\n",
              "  106,\n",
              "  268,\n",
              "  7,\n",
              "  67,\n",
              "  57],\n",
              " [201, 50],\n",
              " [201, 50, 88],\n",
              " [201, 50, 88, 581],\n",
              " [201, 50, 88, 581, 2],\n",
              " [201, 50, 88, 581, 2, 582],\n",
              " [201, 50, 88, 581, 2, 582, 164],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67, 583],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67, 583, 584],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67, 583, 584, 199],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67, 583, 584, 199, 77],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67, 583, 584, 199, 77, 88],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67, 583, 584, 199, 77, 88, 585],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67, 583, 584, 199, 77, 88, 585, 8],\n",
              " [201, 50, 88, 581, 2, 582, 164, 6, 67, 583, 584, 199, 77, 88, 585, 8, 259],\n",
              " [201,\n",
              "  50,\n",
              "  88,\n",
              "  581,\n",
              "  2,\n",
              "  582,\n",
              "  164,\n",
              "  6,\n",
              "  67,\n",
              "  583,\n",
              "  584,\n",
              "  199,\n",
              "  77,\n",
              "  88,\n",
              "  585,\n",
              "  8,\n",
              "  259,\n",
              "  41],\n",
              " [190, 254],\n",
              " [190, 254, 16],\n",
              " [190, 254, 16, 160],\n",
              " [190, 254, 16, 160, 369],\n",
              " [190, 254, 16, 160, 369, 8],\n",
              " [190, 254, 16, 160, 369, 8, 382],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12, 586],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12, 586, 1],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12, 586, 1, 12],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12, 586, 1, 12, 587],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12, 586, 1, 12, 587, 29],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12, 586, 1, 12, 587, 29, 6],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12, 586, 1, 12, 587, 29, 6, 5],\n",
              " [190, 254, 16, 160, 369, 8, 382, 16, 12, 586, 1, 12, 587, 29, 6, 5, 166],\n",
              " [160, 18],\n",
              " [160, 18, 383],\n",
              " [160, 18, 383, 6],\n",
              " [160, 18, 383, 6, 588],\n",
              " [160, 18, 383, 6, 588, 350],\n",
              " [160, 18, 383, 6, 588, 350, 5],\n",
              " [160, 18, 383, 6, 588, 350, 5, 11],\n",
              " [160, 18, 383, 6, 588, 350, 5, 11, 48],\n",
              " [160, 18, 383, 6, 588, 350, 5, 11, 48, 589],\n",
              " [160, 18, 383, 6, 588, 350, 5, 11, 48, 589, 1],\n",
              " [160, 18, 383, 6, 588, 350, 5, 11, 48, 589, 1, 590],\n",
              " [160, 18, 383, 6, 588, 350, 5, 11, 48, 589, 1, 590, 384],\n",
              " [348, 18],\n",
              " [348, 18, 189],\n",
              " [348, 18, 189, 30],\n",
              " [348, 18, 189, 30, 16],\n",
              " [348, 18, 189, 30, 16, 34],\n",
              " [348, 18, 189, 30, 16, 34, 84],\n",
              " [348, 18, 189, 30, 16, 34, 84, 385],\n",
              " [348, 18, 189, 30, 16, 34, 84, 385, 5],\n",
              " [348, 18, 189, 30, 16, 34, 84, 385, 5, 386],\n",
              " [348, 18, 189, 30, 16, 34, 84, 385, 5, 386, 6],\n",
              " [348, 18, 189, 30, 16, 34, 84, 385, 5, 386, 6, 19],\n",
              " [348, 18, 189, 30, 16, 34, 84, 385, 5, 386, 6, 19, 11],\n",
              " [348, 18, 189, 30, 16, 34, 84, 385, 5, 386, 6, 19, 11, 252],\n",
              " [348, 18, 189, 30, 16, 34, 84, 385, 5, 386, 6, 19, 11, 252, 253],\n",
              " [9, 66],\n",
              " [9, 66, 4],\n",
              " [9, 66, 4, 105],\n",
              " [9, 66, 4, 105, 9],\n",
              " [9, 66, 4, 105, 9, 4],\n",
              " [9, 66, 4, 105, 9, 4, 20],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2, 130],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2, 130, 129],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2, 130, 129, 2],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2, 130, 129, 2, 108],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2, 130, 129, 2, 108, 202],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2, 130, 129, 2, 108, 202, 7],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2, 130, 129, 2, 108, 202, 7, 39],\n",
              " [9, 66, 4, 105, 9, 4, 20, 66, 4, 2, 130, 129, 2, 108, 202, 7, 39, 269],\n",
              " [55, 387],\n",
              " [55, 387, 167],\n",
              " [55, 387, 167, 12],\n",
              " [55, 387, 167, 12, 21],\n",
              " [55, 387, 167, 12, 21, 238],\n",
              " [55, 387, 167, 12, 21, 238, 3],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270, 124],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270, 124, 388],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270, 124, 388, 591],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270, 124, 388, 591, 1],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270, 124, 388, 591, 1, 592],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270, 124, 388, 591, 1, 592, 346],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270, 124, 388, 591, 1, 592, 346, 2],\n",
              " [55, 387, 167, 12, 21, 238, 3, 17, 5, 270, 124, 388, 591, 1, 592, 346, 2, 64],\n",
              " [55,\n",
              "  387,\n",
              "  167,\n",
              "  12,\n",
              "  21,\n",
              "  238,\n",
              "  3,\n",
              "  17,\n",
              "  5,\n",
              "  270,\n",
              "  124,\n",
              "  388,\n",
              "  591,\n",
              "  1,\n",
              "  592,\n",
              "  346,\n",
              "  2,\n",
              "  64,\n",
              "  5],\n",
              " [248, 65],\n",
              " [248, 65, 11],\n",
              " [248, 65, 11, 125],\n",
              " [248, 65, 11, 125, 1],\n",
              " [248, 65, 11, 125, 1, 593],\n",
              " [248, 65, 11, 125, 1, 593, 248],\n",
              " [248, 65, 11, 125, 1, 593, 248, 63],\n",
              " [248, 65, 11, 125, 1, 593, 248, 63, 271],\n",
              " [248, 65, 11, 125, 1, 593, 248, 63, 271, 55],\n",
              " [248, 65, 11, 125, 1, 593, 248, 63, 271, 55, 15],\n",
              " [248, 65, 11, 125, 1, 593, 248, 63, 271, 55, 15, 594],\n",
              " [248, 65, 11, 125, 1, 593, 248, 63, 271, 55, 15, 594, 595],\n",
              " [248, 65, 11, 125, 1, 593, 248, 63, 271, 55, 15, 594, 595, 39],\n",
              " [248, 65, 11, 125, 1, 593, 248, 63, 271, 55, 15, 594, 595, 39, 10],\n",
              " [125, 272],\n",
              " [125, 272, 389],\n",
              " [125, 272, 389, 97],\n",
              " [125, 272, 389, 97, 111],\n",
              " [125, 272, 389, 97, 111, 17],\n",
              " [125, 272, 389, 97, 111, 17, 596],\n",
              " [125, 272, 389, 97, 111, 17, 596, 3],\n",
              " [125, 272, 389, 97, 111, 17, 596, 3, 62],\n",
              " [125, 272, 389, 97, 111, 17, 596, 3, 62, 2],\n",
              " [125, 272, 389, 97, 111, 17, 596, 3, 62, 2, 84],\n",
              " [125, 272, 389, 97, 111, 17, 596, 3, 62, 2, 84, 75],\n",
              " [125, 272, 389, 97, 111, 17, 596, 3, 62, 2, 84, 75, 273],\n",
              " [125, 272, 389, 97, 111, 17, 596, 3, 62, 2, 84, 75, 273, 112],\n",
              " [5, 597],\n",
              " [5, 597, 598],\n",
              " [5, 597, 598, 390],\n",
              " [5, 597, 598, 390, 3],\n",
              " [5, 597, 598, 390, 3, 89],\n",
              " [5, 597, 598, 390, 3, 89, 8],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599, 15],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599, 15, 274],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599, 15, 274, 203],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599, 15, 274, 203, 600],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599, 15, 274, 203, 600, 11],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599, 15, 274, 203, 600, 11, 601],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599, 15, 274, 203, 600, 11, 601, 23],\n",
              " [5, 597, 598, 390, 3, 89, 8, 3, 599, 15, 274, 203, 600, 11, 601, 23, 602],\n",
              " [9, 4],\n",
              " [9, 4, 10],\n",
              " [9, 4, 10, 168],\n",
              " [9, 4, 10, 168, 275],\n",
              " [9, 4, 10, 168, 275, 391],\n",
              " [9, 4, 10, 168, 275, 391, 354],\n",
              " [9, 4, 10, 168, 275, 391, 354, 11],\n",
              " [9, 4, 10, 168, 275, 391, 354, 11, 196],\n",
              " [9, 4, 10, 168, 275, 391, 354, 11, 196, 23],\n",
              " [9, 4, 10, 168, 275, 391, 354, 11, 196, 23, 355],\n",
              " [9, 4, 10, 168, 275, 391, 354, 11, 196, 23, 355, 2],\n",
              " [9, 4, 10, 168, 275, 391, 354, 11, 196, 23, 355, 2, 603],\n",
              " [9, 4, 10, 168, 275, 391, 354, 11, 196, 23, 355, 2, 603, 17],\n",
              " [196, 604],\n",
              " [196, 604, 605],\n",
              " [196, 604, 605, 276],\n",
              " [196, 604, 605, 276, 9],\n",
              " [196, 604, 605, 276, 9, 16],\n",
              " [196, 604, 605, 276, 9, 16, 2],\n",
              " [196, 604, 605, 276, 9, 16, 2, 61],\n",
              " [196, 604, 605, 276, 9, 16, 2, 61, 83],\n",
              " [196, 604, 605, 276, 9, 16, 2, 61, 83, 102],\n",
              " [196, 604, 605, 276, 9, 16, 2, 61, 83, 102, 392],\n",
              " [196, 604, 605, 276, 9, 16, 2, 61, 83, 102, 392, 204],\n",
              " [196, 604, 605, 276, 9, 16, 2, 61, 83, 102, 392, 204, 169],\n",
              " [196, 604, 605, 276, 9, 16, 2, 61, 83, 102, 392, 204, 169, 606],\n",
              " [73, 4],\n",
              " [73, 4, 607],\n",
              " [73, 4, 607, 277],\n",
              " [73, 4, 607, 277, 159],\n",
              " [73, 4, 607, 277, 159, 10],\n",
              " [73, 4, 607, 277, 159, 10, 13],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126, 1],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126, 1, 188],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126, 1, 188, 608],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126, 1, 188, 608, 165],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126, 1, 188, 608, 165, 6],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126, 1, 188, 608, 165, 6, 127],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126, 1, 188, 608, 165, 6, 127, 126],\n",
              " [73, 4, 607, 277, 159, 10, 13, 104, 126, 1, 188, 608, 165, 6, 127, 126, 609],\n",
              " [73,\n",
              "  4,\n",
              "  607,\n",
              "  277,\n",
              "  159,\n",
              "  10,\n",
              "  13,\n",
              "  104,\n",
              "  126,\n",
              "  1,\n",
              "  188,\n",
              "  608,\n",
              "  165,\n",
              "  6,\n",
              "  127,\n",
              "  126,\n",
              "  609,\n",
              "  32],\n",
              " [73,\n",
              "  4,\n",
              "  607,\n",
              "  277,\n",
              "  159,\n",
              "  10,\n",
              "  13,\n",
              "  104,\n",
              "  126,\n",
              "  1,\n",
              "  188,\n",
              "  608,\n",
              "  165,\n",
              "  6,\n",
              "  127,\n",
              "  126,\n",
              "  609,\n",
              "  32,\n",
              "  1],\n",
              " [73,\n",
              "  4,\n",
              "  607,\n",
              "  277,\n",
              "  159,\n",
              "  10,\n",
              "  13,\n",
              "  104,\n",
              "  126,\n",
              "  1,\n",
              "  188,\n",
              "  608,\n",
              "  165,\n",
              "  6,\n",
              "  127,\n",
              "  126,\n",
              "  609,\n",
              "  32,\n",
              "  1,\n",
              "  5],\n",
              " [73, 4],\n",
              " [73, 4, 90],\n",
              " [73, 4, 90, 610],\n",
              " [73, 4, 90, 610, 393],\n",
              " [73, 4, 90, 610, 393, 6],\n",
              " [73, 4, 90, 610, 393, 6, 24],\n",
              " [73, 4, 90, 610, 393, 6, 24, 1],\n",
              " [73, 4, 90, 610, 393, 6, 24, 1, 33],\n",
              " [73, 4, 90, 610, 393, 6, 24, 1, 33, 78],\n",
              " [73, 4, 90, 610, 393, 6, 24, 1, 33, 78, 19],\n",
              " [73, 4, 90, 610, 393, 6, 24, 1, 33, 78, 19, 195],\n",
              " [73, 4, 90, 610, 393, 6, 24, 1, 33, 78, 19, 195, 20],\n",
              " [73, 4, 90, 610, 393, 6, 24, 1, 33, 78, 19, 195, 20, 611],\n",
              " [73, 4, 90, 610, 393, 6, 24, 1, 33, 78, 19, 195, 20, 611, 5],\n",
              " [9, 4],\n",
              " [9, 4, 10],\n",
              " [9, 4, 10, 18],\n",
              " [9, 4, 10, 18, 5],\n",
              " [9, 4, 10, 18, 5, 353],\n",
              " [9, 4, 10, 18, 5, 353, 155],\n",
              " [9, 4, 10, 18, 5, 353, 155, 278],\n",
              " [9, 4, 10, 18, 5, 353, 155, 278, 279],\n",
              " [9, 4, 10, 18, 5, 353, 155, 278, 279, 8],\n",
              " [9, 4, 10, 18, 5, 353, 155, 278, 279, 8, 161],\n",
              " [9, 4, 10, 18, 5, 353, 155, 278, 279, 8, 161, 5],\n",
              " [9, 4, 10, 18, 5, 353, 155, 278, 279, 8, 161, 5, 2],\n",
              " [9, 4, 10, 18, 5, 353, 155, 278, 279, 8, 161, 5, 2, 130],\n",
              " [9, 4, 10, 18, 5, 353, 155, 278, 279, 8, 161, 5, 2, 130, 193],\n",
              " [612, 5],\n",
              " [612, 5, 59],\n",
              " [612, 5, 59, 56],\n",
              " [612, 5, 59, 56, 394],\n",
              " [612, 5, 59, 56, 394, 1],\n",
              " [612, 5, 59, 56, 394, 1, 32],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613, 195],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613, 195, 6],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613, 195, 6, 391],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613, 195, 6, 391, 19],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613, 195, 6, 391, 19, 11],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613, 195, 6, 391, 19, 11, 280],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613, 195, 6, 391, 19, 11, 280, 24],\n",
              " [612, 5, 59, 56, 394, 1, 32, 613, 195, 6, 391, 19, 11, 280, 24, 122],\n",
              " [351, 11],\n",
              " [351, 11, 255],\n",
              " [351, 11, 255, 1],\n",
              " [351, 11, 255, 1, 352],\n",
              " [351, 11, 255, 1, 352, 106],\n",
              " [351, 11, 255, 1, 352, 106, 192],\n",
              " [351, 11, 255, 1, 352, 106, 192, 256],\n",
              " [351, 11, 255, 1, 352, 106, 192, 256, 18],\n",
              " [351, 11, 255, 1, 352, 106, 192, 256, 18, 29],\n",
              " [351, 11, 255, 1, 352, 106, 192, 256, 18, 29, 2],\n",
              " [351, 11, 255, 1, 352, 106, 192, 256, 18, 29, 2, 614],\n",
              " [351, 11, 255, 1, 352, 106, 192, 256, 18, 29, 2, 614, 121],\n",
              " [351, 11, 255, 1, 352, 106, 192, 256, 18, 29, 2, 614, 121, 111],\n",
              " [351, 11, 255, 1, 352, 106, 192, 256, 18, 29, 2, 614, 121, 111, 17],\n",
              " [255, 105],\n",
              " [255, 105, 3],\n",
              " [255, 105, 3, 615],\n",
              " [255, 105, 3, 615, 8],\n",
              " [255, 105, 3, 615, 8, 616],\n",
              " [255, 105, 3, 615, 8, 616, 1],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617, 4],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617, 4, 618],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617, 4, 618, 168],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617, 4, 618, 168, 395],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617, 4, 618, 168, 395, 135],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617, 4, 618, 168, 395, 135, 237],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617, 4, 618, 168, 395, 135, 237, 169],\n",
              " [255, 105, 3, 615, 8, 616, 1, 617, 4, 618, 168, 395, 135, 237, 169, 256],\n",
              " [619, 11],\n",
              " [619, 11, 4],\n",
              " [619, 11, 4, 281],\n",
              " [619, 11, 4, 281, 138],\n",
              " [619, 11, 4, 281, 138, 89],\n",
              " [619, 11, 4, 281, 138, 89, 1],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62, 139],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62, 139, 620],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62, 139, 620, 56],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62, 139, 620, 56, 621],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62, 139, 620, 56, 621, 250],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62, 139, 620, 56, 621, 250, 6],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62, 139, 620, 56, 621, 250, 6, 622],\n",
              " [619, 11, 4, 281, 138, 89, 1, 62, 139, 620, 56, 621, 250, 6, 622, 25],\n",
              " [282, 205],\n",
              " [282, 205, 91],\n",
              " [282, 205, 91, 283],\n",
              " [282, 205, 91, 283, 3],\n",
              " [282, 205, 91, 283, 3, 264],\n",
              " [282, 205, 91, 283, 3, 264, 25],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15, 623],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15, 623, 3],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15, 623, 3, 5],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15, 623, 3, 5, 68],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15, 623, 3, 5, 68, 17],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15, 623, 3, 5, 68, 17, 1],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15, 623, 3, 5, 68, 17, 1, 205],\n",
              " [282, 205, 91, 283, 3, 264, 25, 15, 623, 3, 5, 68, 17, 1, 205, 396],\n",
              " [284, 397],\n",
              " [284, 397, 398],\n",
              " [284, 397, 398, 55],\n",
              " [284, 397, 398, 55, 15],\n",
              " [284, 397, 398, 55, 15, 624],\n",
              " [284, 397, 398, 55, 15, 624, 17],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3, 264],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3, 264, 25],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3, 264, 25, 13],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3, 264, 25, 13, 3],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3, 264, 25, 13, 3, 205],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3, 264, 25, 13, 3, 205, 399],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3, 264, 25, 13, 3, 205, 399, 625],\n",
              " [284, 397, 398, 55, 15, 624, 17, 206, 3, 264, 25, 13, 3, 205, 399, 625, 113],\n",
              " [376, 150],\n",
              " [376, 150, 11],\n",
              " [376, 150, 11, 626],\n",
              " [376, 150, 11, 626, 627],\n",
              " [376, 150, 11, 626, 627, 262],\n",
              " [376, 150, 11, 626, 627, 262, 628],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282, 629],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282, 629, 18],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282, 629, 18, 29],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282, 629, 18, 29, 2],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282, 629, 18, 29, 2, 630],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282, 629, 18, 29, 2, 630, 285],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282, 629, 18, 29, 2, 630, 285, 124],\n",
              " [376, 150, 11, 626, 627, 262, 628, 23, 282, 629, 18, 29, 2, 630, 285, 124, 3],\n",
              " [376,\n",
              "  150,\n",
              "  11,\n",
              "  626,\n",
              "  627,\n",
              "  262,\n",
              "  628,\n",
              "  23,\n",
              "  282,\n",
              "  629,\n",
              "  18,\n",
              "  29,\n",
              "  2,\n",
              "  630,\n",
              "  285,\n",
              "  124,\n",
              "  3,\n",
              "  21],\n",
              " [376,\n",
              "  150,\n",
              "  11,\n",
              "  626,\n",
              "  627,\n",
              "  262,\n",
              "  628,\n",
              "  23,\n",
              "  282,\n",
              "  629,\n",
              "  18,\n",
              "  29,\n",
              "  2,\n",
              "  630,\n",
              "  285,\n",
              "  124,\n",
              "  3,\n",
              "  21,\n",
              "  286],\n",
              " [9, 4],\n",
              " [9, 4, 90],\n",
              " [9, 4, 90, 400],\n",
              " [9, 4, 90, 400, 245],\n",
              " [9, 4, 90, 400, 245, 11],\n",
              " [9, 4, 90, 400, 245, 11, 123],\n",
              " [9, 4, 90, 400, 245, 11, 123, 100],\n",
              " [9, 4, 90, 400, 245, 11, 123, 100, 137],\n",
              " [9, 4, 90, 400, 245, 11, 123, 100, 137, 44],\n",
              " [9, 4, 90, 400, 245, 11, 123, 100, 137, 44, 49],\n",
              " [9, 4, 90, 400, 245, 11, 123, 100, 137, 44, 49, 1],\n",
              " [9, 4, 90, 400, 245, 11, 123, 100, 137, 44, 49, 1, 72],\n",
              " [9, 4, 90, 400, 245, 11, 123, 100, 137, 44, 49, 1, 72, 54],\n",
              " [92, 42],\n",
              " [92, 42, 1],\n",
              " [92, 42, 1, 24],\n",
              " [92, 42, 1, 24, 93],\n",
              " [92, 42, 1, 24, 93, 18],\n",
              " [92, 42, 1, 24, 93, 18, 207],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19, 170],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19, 170, 123],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19, 170, 123, 100],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19, 170, 123, 100, 34],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19, 170, 123, 100, 34, 131],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19, 170, 123, 100, 34, 131, 401],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19, 170, 123, 100, 34, 131, 401, 631],\n",
              " [92, 42, 1, 24, 93, 18, 207, 19, 170, 123, 100, 34, 131, 401, 631, 632],\n",
              " [7, 101],\n",
              " [7, 101, 9],\n",
              " [7, 101, 9, 4],\n",
              " [7, 101, 9, 4, 10],\n",
              " [7, 101, 9, 4, 10, 131],\n",
              " [7, 101, 9, 4, 10, 131, 633],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19, 11],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19, 11, 70],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19, 11, 70, 114],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19, 11, 70, 114, 33],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19, 11, 70, 114, 33, 166],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19, 11, 70, 114, 33, 166, 1],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19, 11, 70, 114, 33, 166, 1, 287],\n",
              " [7, 101, 9, 4, 10, 131, 633, 634, 19, 11, 70, 114, 33, 166, 1, 287, 122],\n",
              " [635, 18],\n",
              " [635, 18, 12],\n",
              " [635, 18, 12, 191],\n",
              " [635, 18, 12, 191, 8],\n",
              " [635, 18, 12, 191, 8, 21],\n",
              " [635, 18, 12, 191, 8, 21, 139],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636, 3],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636, 3, 637],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636, 3, 637, 6],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636, 3, 637, 6, 402],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636, 3, 637, 6, 402, 8],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636, 3, 637, 6, 402, 8, 3],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636, 3, 637, 6, 402, 8, 3, 403],\n",
              " [635, 18, 12, 191, 8, 21, 139, 34, 90, 636, 3, 637, 6, 402, 8, 3, 403, 101],\n",
              " [635,\n",
              "  18,\n",
              "  12,\n",
              "  191,\n",
              "  8,\n",
              "  21,\n",
              "  139,\n",
              "  34,\n",
              "  90,\n",
              "  636,\n",
              "  3,\n",
              "  637,\n",
              "  6,\n",
              "  402,\n",
              "  8,\n",
              "  3,\n",
              "  403,\n",
              "  101,\n",
              "  10],\n",
              " [635,\n",
              "  18,\n",
              "  12,\n",
              "  191,\n",
              "  8,\n",
              "  21,\n",
              "  139,\n",
              "  34,\n",
              "  90,\n",
              "  636,\n",
              "  3,\n",
              "  637,\n",
              "  6,\n",
              "  402,\n",
              "  8,\n",
              "  3,\n",
              "  403,\n",
              "  101,\n",
              "  10,\n",
              "  11],\n",
              " [635,\n",
              "  18,\n",
              "  12,\n",
              "  191,\n",
              "  8,\n",
              "  21,\n",
              "  139,\n",
              "  34,\n",
              "  90,\n",
              "  636,\n",
              "  3,\n",
              "  637,\n",
              "  6,\n",
              "  402,\n",
              "  8,\n",
              "  3,\n",
              "  403,\n",
              "  101,\n",
              "  10,\n",
              "  11,\n",
              "  288],\n",
              " [3, 638],\n",
              " [3, 638, 21],\n",
              " [3, 638, 21, 400],\n",
              " [3, 638, 21, 400, 101],\n",
              " [3, 638, 21, 400, 101, 15],\n",
              " [3, 638, 21, 400, 101, 15, 98],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13, 639],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13, 639, 640],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13, 639, 640, 8],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13, 639, 640, 8, 33],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13, 639, 640, 8, 33, 6],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13, 639, 640, 8, 33, 6, 12],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13, 639, 640, 8, 33, 6, 12, 641],\n",
              " [3, 638, 21, 400, 101, 15, 98, 277, 17, 13, 639, 640, 8, 33, 6, 12, 641, 642],\n",
              " [3,\n",
              "  638,\n",
              "  21,\n",
              "  400,\n",
              "  101,\n",
              "  15,\n",
              "  98,\n",
              "  277,\n",
              "  17,\n",
              "  13,\n",
              "  639,\n",
              "  640,\n",
              "  8,\n",
              "  33,\n",
              "  6,\n",
              "  12,\n",
              "  641,\n",
              "  642,\n",
              "  8],\n",
              " [3,\n",
              "  638,\n",
              "  21,\n",
              "  400,\n",
              "  101,\n",
              "  15,\n",
              "  98,\n",
              "  277,\n",
              "  17,\n",
              "  13,\n",
              "  639,\n",
              "  640,\n",
              "  8,\n",
              "  33,\n",
              "  6,\n",
              "  12,\n",
              "  641,\n",
              "  642,\n",
              "  8,\n",
              "  19],\n",
              " [288, 643],\n",
              " [288, 643, 12],\n",
              " [288, 643, 12, 83],\n",
              " [288, 643, 12, 83, 644],\n",
              " [288, 643, 12, 83, 644, 21],\n",
              " [288, 643, 12, 83, 644, 21, 90],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8, 3],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8, 3, 403],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8, 3, 403, 237],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8, 3, 403, 237, 7],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8, 3, 403, 237, 7, 137],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8, 3, 403, 237, 7, 137, 44],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8, 3, 403, 237, 7, 137, 44, 404],\n",
              " [288, 643, 12, 83, 644, 21, 90, 645, 402, 8, 3, 403, 237, 7, 137, 44, 404, 1],\n",
              " [288,\n",
              "  643,\n",
              "  12,\n",
              "  83,\n",
              "  644,\n",
              "  21,\n",
              "  90,\n",
              "  645,\n",
              "  402,\n",
              "  8,\n",
              "  3,\n",
              "  403,\n",
              "  237,\n",
              "  7,\n",
              "  137,\n",
              "  44,\n",
              "  404,\n",
              "  1,\n",
              "  166],\n",
              " [60, 289],\n",
              " [60, 289, 7],\n",
              " [60, 289, 7, 9],\n",
              " [60, 289, 7, 9, 4],\n",
              " [60, 289, 7, 9, 4, 63],\n",
              " [60, 289, 7, 9, 4, 63, 10],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94, 8],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94, 8, 36],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94, 8, 36, 5],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94, 8, 36, 5, 113],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94, 8, 36, 5, 113, 25],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94, 8, 36, 5, 113, 25, 13],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94, 8, 36, 5, 113, 25, 13, 71],\n",
              " [60, 289, 7, 9, 4, 63, 10, 140, 13, 141, 94, 8, 36, 5, 113, 25, 13, 71, 19],\n",
              " [290, 208],\n",
              " [290, 208, 4],\n",
              " [290, 208, 4, 35],\n",
              " [290, 208, 4, 35, 405],\n",
              " [290, 208, 4, 35, 405, 5],\n",
              " [290, 208, 4, 35, 405, 5, 15],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8, 5],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8, 5, 45],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8, 5, 45, 209],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8, 5, 45, 209, 94],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8, 5, 45, 209, 94, 261],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8, 5, 45, 209, 94, 261, 130],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8, 5, 45, 209, 94, 261, 130, 10],\n",
              " [290, 208, 4, 35, 405, 5, 15, 291, 94, 8, 5, 45, 209, 94, 261, 130, 10, 20],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in arr])"
      ],
      "metadata": {
        "id": "XFieudfIM1i3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TxPAjGiM1oI",
        "outputId": "4c9d3884-613a-463e-edc1-0907726667fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_data = pad_sequences(arr,maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "qg1MvJMyM1qs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttsgVNLBM1tK",
        "outputId": "43407721-476c-46d9-9303-c0c69e5afaf1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    9,    4],\n",
              "       [   0,    0,    0, ...,    9,    4,   14],\n",
              "       [   0,    0,    0, ...,    4,   14,   12],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 1065,    1,  229],\n",
              "       [   0,    0,    0, ...,    1,  229,  110],\n",
              "       [   0,    0,    0, ...,  229,  110, 1066]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk_ffjbL1t_r",
        "outputId": "56d5fd5d-9d6e-4336-fa3c-dd77cae9365e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3855, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_input_data[:,:-1]\n",
        "y = padded_input_data[:,-1]"
      ],
      "metadata": {
        "id": "QUJKQEIqNr9N"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH-xqlAJOGfg",
        "outputId": "c0be2d51-989a-443a-8ed6-41daa8899995"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3855, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3Pi91HIOJ0N",
        "outputId": "01193eec-6212-4881-92d7-8212c34fb366"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3855,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "JV1gTJeMOLRt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes =1067)"
      ],
      "metadata": {
        "id": "CBCoUkSuQYlh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6fMitWcQpM_",
        "outputId": "adb26990-5648-43aa-e9c4-f721c49aa28a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(1067,550,input_length = 23))\n",
        "model.add(LSTM(250))\n",
        "\n",
        "model.add(Dense(1067,activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpGnHCCtQ4WA",
        "outputId": "862c4bb6-9fe4-4ad5-d6a6-4d66ef83fbbc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "UeKrgPCcSR0I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x,y,epochs = 425)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzz58jHqSdnK",
        "outputId": "ce1b97ac-7d5e-4ac8-e88d-5c1244a59307"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0268 - loss: 6.5532\n",
            "Epoch 2/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0550 - loss: 5.8082\n",
            "Epoch 3/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.0771 - loss: 5.4919\n",
            "Epoch 4/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.1436 - loss: 4.9725\n",
            "Epoch 5/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2141 - loss: 4.3239\n",
            "Epoch 6/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3013 - loss: 3.6354\n",
            "Epoch 7/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3980 - loss: 3.0104\n",
            "Epoch 8/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5038 - loss: 2.4469\n",
            "Epoch 9/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6101 - loss: 1.9948\n",
            "Epoch 10/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6987 - loss: 1.5848\n",
            "Epoch 11/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7949 - loss: 1.2397\n",
            "Epoch 12/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8551 - loss: 0.9705\n",
            "Epoch 13/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8885 - loss: 0.7497\n",
            "Epoch 14/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9245 - loss: 0.5901\n",
            "Epoch 15/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9288 - loss: 0.4910\n",
            "Epoch 16/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9375 - loss: 0.4083\n",
            "Epoch 17/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.3460\n",
            "Epoch 18/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9529 - loss: 0.2864\n",
            "Epoch 19/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9458 - loss: 0.2591\n",
            "Epoch 20/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.2281\n",
            "Epoch 21/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.2051\n",
            "Epoch 22/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9483 - loss: 0.2007\n",
            "Epoch 23/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9562 - loss: 0.1791\n",
            "Epoch 24/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1633\n",
            "Epoch 25/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.1658\n",
            "Epoch 26/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1585\n",
            "Epoch 27/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9503 - loss: 0.1626\n",
            "Epoch 28/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9550 - loss: 0.1351\n",
            "Epoch 29/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9511 - loss: 0.1473\n",
            "Epoch 30/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9544 - loss: 0.1338\n",
            "Epoch 31/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9503 - loss: 0.1399\n",
            "Epoch 32/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9505 - loss: 0.1331\n",
            "Epoch 33/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9504 - loss: 0.1285\n",
            "Epoch 34/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9535 - loss: 0.1254\n",
            "Epoch 35/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9469 - loss: 0.1328\n",
            "Epoch 36/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9530 - loss: 0.1301\n",
            "Epoch 37/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9502 - loss: 0.1249\n",
            "Epoch 38/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9484 - loss: 0.1237\n",
            "Epoch 39/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9530 - loss: 0.1189\n",
            "Epoch 40/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.1186\n",
            "Epoch 41/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9524 - loss: 0.1134\n",
            "Epoch 42/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9606 - loss: 0.0993\n",
            "Epoch 43/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9611 - loss: 0.0994\n",
            "Epoch 44/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9568 - loss: 0.1041\n",
            "Epoch 45/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9495 - loss: 0.1273\n",
            "Epoch 46/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.1202\n",
            "Epoch 47/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9623 - loss: 0.0916\n",
            "Epoch 48/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.0997\n",
            "Epoch 49/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9533 - loss: 0.1090\n",
            "Epoch 50/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9560 - loss: 0.1008\n",
            "Epoch 51/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9568 - loss: 0.1012\n",
            "Epoch 52/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9565 - loss: 0.1009\n",
            "Epoch 53/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9494 - loss: 0.1162\n",
            "Epoch 54/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9531 - loss: 0.1037\n",
            "Epoch 55/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.1050\n",
            "Epoch 56/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9533 - loss: 0.1040\n",
            "Epoch 57/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9519 - loss: 0.1041\n",
            "Epoch 58/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9463 - loss: 0.1157\n",
            "Epoch 59/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9536 - loss: 0.1034\n",
            "Epoch 60/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9533 - loss: 0.1006\n",
            "Epoch 61/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.1030\n",
            "Epoch 62/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9510 - loss: 0.0983\n",
            "Epoch 63/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9548 - loss: 0.1064\n",
            "Epoch 64/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9527 - loss: 0.0987\n",
            "Epoch 65/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9499 - loss: 0.1108\n",
            "Epoch 66/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9531 - loss: 0.1013\n",
            "Epoch 67/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9574 - loss: 0.0911\n",
            "Epoch 68/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9582 - loss: 0.0914\n",
            "Epoch 69/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9568 - loss: 0.0951\n",
            "Epoch 70/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9572 - loss: 0.0953\n",
            "Epoch 71/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.0991\n",
            "Epoch 72/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9493 - loss: 0.1026\n",
            "Epoch 73/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9622 - loss: 0.0869\n",
            "Epoch 74/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9531 - loss: 0.0947\n",
            "Epoch 75/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9548 - loss: 0.0922\n",
            "Epoch 76/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1025\n",
            "Epoch 77/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9615 - loss: 0.0871\n",
            "Epoch 78/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.1017\n",
            "Epoch 79/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9525 - loss: 0.1011\n",
            "Epoch 80/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9540 - loss: 0.0958\n",
            "Epoch 81/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9522 - loss: 0.0999\n",
            "Epoch 82/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.0952\n",
            "Epoch 83/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9576 - loss: 0.0918\n",
            "Epoch 84/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9632 - loss: 0.0838\n",
            "Epoch 85/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9514 - loss: 0.1003\n",
            "Epoch 86/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9545 - loss: 0.0988\n",
            "Epoch 87/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9588 - loss: 0.0907\n",
            "Epoch 88/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.0985\n",
            "Epoch 89/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9485 - loss: 0.1000\n",
            "Epoch 90/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9524 - loss: 0.0945\n",
            "Epoch 91/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9625 - loss: 0.0788\n",
            "Epoch 92/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9542 - loss: 0.0928\n",
            "Epoch 93/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9438 - loss: 0.1123\n",
            "Epoch 94/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9547 - loss: 0.0867\n",
            "Epoch 95/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9561 - loss: 0.0986\n",
            "Epoch 96/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9034 - loss: 0.3119\n",
            "Epoch 97/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9285 - loss: 0.1952\n",
            "Epoch 98/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9506 - loss: 0.1217\n",
            "Epoch 99/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9549 - loss: 0.1036\n",
            "Epoch 100/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.0921\n",
            "Epoch 101/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9557 - loss: 0.1016\n",
            "Epoch 102/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9536 - loss: 0.0990\n",
            "Epoch 103/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.0981\n",
            "Epoch 104/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9566 - loss: 0.0992\n",
            "Epoch 105/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.1024\n",
            "Epoch 106/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9574 - loss: 0.0928\n",
            "Epoch 107/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.0920\n",
            "Epoch 108/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9524 - loss: 0.1008\n",
            "Epoch 109/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9544 - loss: 0.0944\n",
            "Epoch 110/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9560 - loss: 0.0956\n",
            "Epoch 111/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9526 - loss: 0.0963\n",
            "Epoch 112/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9495 - loss: 0.0963\n",
            "Epoch 113/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9585 - loss: 0.0952\n",
            "Epoch 114/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9601 - loss: 0.0919\n",
            "Epoch 115/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.0910\n",
            "Epoch 116/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9466 - loss: 0.1058\n",
            "Epoch 117/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9588 - loss: 0.0864\n",
            "Epoch 118/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9564 - loss: 0.0873\n",
            "Epoch 119/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9538 - loss: 0.0950\n",
            "Epoch 120/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9588 - loss: 0.0836\n",
            "Epoch 121/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9496 - loss: 0.0943\n",
            "Epoch 122/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9532 - loss: 0.0987\n",
            "Epoch 123/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9579 - loss: 0.0916\n",
            "Epoch 124/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9572 - loss: 0.0957\n",
            "Epoch 125/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9536 - loss: 0.0956\n",
            "Epoch 126/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9593 - loss: 0.0846\n",
            "Epoch 127/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9545 - loss: 0.0887\n",
            "Epoch 128/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9560 - loss: 0.0909\n",
            "Epoch 129/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9569 - loss: 0.0882\n",
            "Epoch 130/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.0955\n",
            "Epoch 131/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.1047\n",
            "Epoch 132/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9552 - loss: 0.0934\n",
            "Epoch 133/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9578 - loss: 0.0864\n",
            "Epoch 134/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.0993\n",
            "Epoch 135/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.0942\n",
            "Epoch 136/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.1032\n",
            "Epoch 137/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9563 - loss: 0.0925\n",
            "Epoch 138/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9602 - loss: 0.0817\n",
            "Epoch 139/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9572 - loss: 0.0921\n",
            "Epoch 140/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9601 - loss: 0.0871\n",
            "Epoch 141/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9559 - loss: 0.0911\n",
            "Epoch 142/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9593 - loss: 0.0884\n",
            "Epoch 143/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9590 - loss: 0.0880\n",
            "Epoch 144/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.0904\n",
            "Epoch 145/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9557 - loss: 0.0916\n",
            "Epoch 146/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9596 - loss: 0.0892\n",
            "Epoch 147/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9545 - loss: 0.0974\n",
            "Epoch 148/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9594 - loss: 0.0823\n",
            "Epoch 149/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9551 - loss: 0.0896\n",
            "Epoch 150/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9620 - loss: 0.0792\n",
            "Epoch 151/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9583 - loss: 0.0879\n",
            "Epoch 152/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9496 - loss: 0.0998\n",
            "Epoch 153/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.0888\n",
            "Epoch 154/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.0977\n",
            "Epoch 155/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9541 - loss: 0.0948\n",
            "Epoch 156/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9498 - loss: 0.0983\n",
            "Epoch 157/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9548 - loss: 0.0979\n",
            "Epoch 158/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9567 - loss: 0.0952\n",
            "Epoch 159/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9544 - loss: 0.0888\n",
            "Epoch 160/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9564 - loss: 0.0896\n",
            "Epoch 161/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.0841\n",
            "Epoch 162/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9496 - loss: 0.0954\n",
            "Epoch 163/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9583 - loss: 0.0913\n",
            "Epoch 164/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9493 - loss: 0.1012\n",
            "Epoch 165/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9524 - loss: 0.0965\n",
            "Epoch 166/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9542 - loss: 0.0942\n",
            "Epoch 167/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 0.0893\n",
            "Epoch 168/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9543 - loss: 0.0925\n",
            "Epoch 169/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9522 - loss: 0.0968\n",
            "Epoch 170/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9604 - loss: 0.0804\n",
            "Epoch 171/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9548 - loss: 0.0975\n",
            "Epoch 172/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.0972\n",
            "Epoch 173/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.0990\n",
            "Epoch 174/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.0851\n",
            "Epoch 175/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9551 - loss: 0.0911\n",
            "Epoch 176/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.0892\n",
            "Epoch 177/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9534 - loss: 0.0945\n",
            "Epoch 178/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9534 - loss: 0.0912\n",
            "Epoch 179/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9530 - loss: 0.0891\n",
            "Epoch 180/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9497 - loss: 0.0977\n",
            "Epoch 181/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9602 - loss: 0.0870\n",
            "Epoch 182/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9541 - loss: 0.0896\n",
            "Epoch 183/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9547 - loss: 0.0995\n",
            "Epoch 184/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9592 - loss: 0.0905\n",
            "Epoch 185/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.0924\n",
            "Epoch 186/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.0982\n",
            "Epoch 187/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.0930\n",
            "Epoch 188/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.0902\n",
            "Epoch 189/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9475 - loss: 0.1016\n",
            "Epoch 190/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.0943\n",
            "Epoch 191/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9550 - loss: 0.0926\n",
            "Epoch 192/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9544 - loss: 0.0866\n",
            "Epoch 193/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9479 - loss: 0.0985\n",
            "Epoch 194/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.0893\n",
            "Epoch 195/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9529 - loss: 0.0963\n",
            "Epoch 196/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.0823\n",
            "Epoch 197/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9601 - loss: 0.0818\n",
            "Epoch 198/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9580 - loss: 0.0918\n",
            "Epoch 199/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9563 - loss: 0.0874\n",
            "Epoch 200/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9574 - loss: 0.0852\n",
            "Epoch 201/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9498 - loss: 0.1095\n",
            "Epoch 202/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9250 - loss: 0.2040\n",
            "Epoch 203/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.1072\n",
            "Epoch 204/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9533 - loss: 0.1018\n",
            "Epoch 205/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9516 - loss: 0.0973\n",
            "Epoch 206/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9540 - loss: 0.0931\n",
            "Epoch 207/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 0.0871\n",
            "Epoch 208/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9527 - loss: 0.0923\n",
            "Epoch 209/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9562 - loss: 0.0996\n",
            "Epoch 210/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.0881\n",
            "Epoch 211/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9511 - loss: 0.0985\n",
            "Epoch 212/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9563 - loss: 0.0892\n",
            "Epoch 213/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9591 - loss: 0.0893\n",
            "Epoch 214/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9485 - loss: 0.0961\n",
            "Epoch 215/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9499 - loss: 0.0945\n",
            "Epoch 216/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.0929\n",
            "Epoch 217/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9581 - loss: 0.0831\n",
            "Epoch 218/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.0869\n",
            "Epoch 219/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.0911\n",
            "Epoch 220/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.0908\n",
            "Epoch 221/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9471 - loss: 0.1008\n",
            "Epoch 222/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9474 - loss: 0.1025\n",
            "Epoch 223/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9593 - loss: 0.0917\n",
            "Epoch 224/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9505 - loss: 0.0940\n",
            "Epoch 225/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9595 - loss: 0.0831\n",
            "Epoch 226/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.0835\n",
            "Epoch 227/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9578 - loss: 0.0848\n",
            "Epoch 228/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9472 - loss: 0.1017\n",
            "Epoch 229/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9542 - loss: 0.0938\n",
            "Epoch 230/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9532 - loss: 0.0940\n",
            "Epoch 231/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9538 - loss: 0.0894\n",
            "Epoch 232/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.0800\n",
            "Epoch 233/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9568 - loss: 0.0902\n",
            "Epoch 234/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9607 - loss: 0.0888\n",
            "Epoch 235/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9544 - loss: 0.0910\n",
            "Epoch 236/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9581 - loss: 0.0943\n",
            "Epoch 237/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9544 - loss: 0.0898\n",
            "Epoch 238/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9510 - loss: 0.1023\n",
            "Epoch 239/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9548 - loss: 0.0974\n",
            "Epoch 240/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9549 - loss: 0.0900\n",
            "Epoch 241/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9515 - loss: 0.0985\n",
            "Epoch 242/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9593 - loss: 0.0861\n",
            "Epoch 243/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9536 - loss: 0.0867\n",
            "Epoch 244/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9540 - loss: 0.0933\n",
            "Epoch 245/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9490 - loss: 0.0995\n",
            "Epoch 246/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.0873\n",
            "Epoch 247/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9566 - loss: 0.0877\n",
            "Epoch 248/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9531 - loss: 0.0911\n",
            "Epoch 249/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9541 - loss: 0.0951\n",
            "Epoch 250/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.0884\n",
            "Epoch 251/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9517 - loss: 0.0926\n",
            "Epoch 252/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9575 - loss: 0.0880\n",
            "Epoch 253/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9541 - loss: 0.0931\n",
            "Epoch 254/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.0891\n",
            "Epoch 255/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9466 - loss: 0.0977\n",
            "Epoch 256/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.0961\n",
            "Epoch 257/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.0919\n",
            "Epoch 258/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9500 - loss: 0.0965\n",
            "Epoch 259/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9542 - loss: 0.0839\n",
            "Epoch 260/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.1013\n",
            "Epoch 261/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9534 - loss: 0.0950\n",
            "Epoch 262/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9531 - loss: 0.1000\n",
            "Epoch 263/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9538 - loss: 0.0942\n",
            "Epoch 264/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9534 - loss: 0.0911\n",
            "Epoch 265/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9594 - loss: 0.0846\n",
            "Epoch 266/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.0889\n",
            "Epoch 267/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9622 - loss: 0.0785\n",
            "Epoch 268/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9580 - loss: 0.0864\n",
            "Epoch 269/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9541 - loss: 0.0939\n",
            "Epoch 270/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9540 - loss: 0.0858\n",
            "Epoch 271/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9559 - loss: 0.0866\n",
            "Epoch 272/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9534 - loss: 0.0942\n",
            "Epoch 273/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9513 - loss: 0.0983\n",
            "Epoch 274/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.0946\n",
            "Epoch 275/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9448 - loss: 0.0977\n",
            "Epoch 276/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9508 - loss: 0.0887\n",
            "Epoch 277/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9498 - loss: 0.1026\n",
            "Epoch 278/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9538 - loss: 0.0911\n",
            "Epoch 279/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9506 - loss: 0.0939\n",
            "Epoch 280/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.0911\n",
            "Epoch 281/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9509 - loss: 0.0937\n",
            "Epoch 282/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.0883\n",
            "Epoch 283/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.0943\n",
            "Epoch 284/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9347 - loss: 0.1511\n",
            "Epoch 285/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9451 - loss: 0.1320\n",
            "Epoch 286/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.0991\n",
            "Epoch 287/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9554 - loss: 0.0910\n",
            "Epoch 288/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.1014\n",
            "Epoch 289/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.0862\n",
            "Epoch 290/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.0874\n",
            "Epoch 291/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9602 - loss: 0.0833\n",
            "Epoch 292/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9538 - loss: 0.0920\n",
            "Epoch 293/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.0899\n",
            "Epoch 294/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.0963\n",
            "Epoch 295/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9566 - loss: 0.0894\n",
            "Epoch 296/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.0870\n",
            "Epoch 297/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9535 - loss: 0.1013\n",
            "Epoch 298/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9532 - loss: 0.0942\n",
            "Epoch 299/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9566 - loss: 0.0848\n",
            "Epoch 300/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9548 - loss: 0.0877\n",
            "Epoch 301/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9545 - loss: 0.0910\n",
            "Epoch 302/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9494 - loss: 0.0969\n",
            "Epoch 303/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.0868\n",
            "Epoch 304/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.0919\n",
            "Epoch 305/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.0931\n",
            "Epoch 306/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9507 - loss: 0.1011\n",
            "Epoch 307/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9590 - loss: 0.0895\n",
            "Epoch 308/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9532 - loss: 0.0807\n",
            "Epoch 309/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9548 - loss: 0.0900\n",
            "Epoch 310/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9562 - loss: 0.0891\n",
            "Epoch 311/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9564 - loss: 0.0829\n",
            "Epoch 312/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9481 - loss: 0.0970\n",
            "Epoch 313/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.0955\n",
            "Epoch 314/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9601 - loss: 0.0794\n",
            "Epoch 315/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9535 - loss: 0.0942\n",
            "Epoch 316/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9555 - loss: 0.0899\n",
            "Epoch 317/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9502 - loss: 0.0994\n",
            "Epoch 318/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.1015\n",
            "Epoch 319/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.0920\n",
            "Epoch 320/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9534 - loss: 0.0907\n",
            "Epoch 321/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9560 - loss: 0.0826\n",
            "Epoch 322/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.0888\n",
            "Epoch 323/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9518 - loss: 0.0924\n",
            "Epoch 324/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.0963\n",
            "Epoch 325/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0964\n",
            "Epoch 326/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.0950\n",
            "Epoch 327/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9529 - loss: 0.0931\n",
            "Epoch 328/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9544 - loss: 0.0879\n",
            "Epoch 329/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9511 - loss: 0.0998\n",
            "Epoch 330/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9605 - loss: 0.0861\n",
            "Epoch 331/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9522 - loss: 0.0937\n",
            "Epoch 332/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.0938\n",
            "Epoch 333/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.0938\n",
            "Epoch 334/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9551 - loss: 0.0912\n",
            "Epoch 335/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9490 - loss: 0.0977\n",
            "Epoch 336/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.0926\n",
            "Epoch 337/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 0.0993\n",
            "Epoch 338/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9570 - loss: 0.0884\n",
            "Epoch 339/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9571 - loss: 0.0772\n",
            "Epoch 340/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.0922\n",
            "Epoch 341/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.0792\n",
            "Epoch 342/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.0875\n",
            "Epoch 343/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9558 - loss: 0.0905\n",
            "Epoch 344/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9587 - loss: 0.0792\n",
            "Epoch 345/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9488 - loss: 0.1018\n",
            "Epoch 346/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9587 - loss: 0.0883\n",
            "Epoch 347/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.1003\n",
            "Epoch 348/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9484 - loss: 0.0964\n",
            "Epoch 349/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9571 - loss: 0.0891\n",
            "Epoch 350/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.0885\n",
            "Epoch 351/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9528 - loss: 0.0931\n",
            "Epoch 352/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.0851\n",
            "Epoch 353/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9624 - loss: 0.0872\n",
            "Epoch 354/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.0924\n",
            "Epoch 355/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.0827\n",
            "Epoch 356/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9502 - loss: 0.0975\n",
            "Epoch 357/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9588 - loss: 0.0781\n",
            "Epoch 358/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9551 - loss: 0.0860\n",
            "Epoch 359/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9511 - loss: 0.0900\n",
            "Epoch 360/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9509 - loss: 0.0967\n",
            "Epoch 361/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9580 - loss: 0.0927\n",
            "Epoch 362/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.0974\n",
            "Epoch 363/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9528 - loss: 0.0903\n",
            "Epoch 364/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9506 - loss: 0.0950\n",
            "Epoch 365/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9528 - loss: 0.0962\n",
            "Epoch 366/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9544 - loss: 0.0857\n",
            "Epoch 367/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9481 - loss: 0.0955\n",
            "Epoch 368/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.0899\n",
            "Epoch 369/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9532 - loss: 0.0867\n",
            "Epoch 370/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.0875\n",
            "Epoch 371/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9581 - loss: 0.0829\n",
            "Epoch 372/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9544 - loss: 0.0905\n",
            "Epoch 373/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.0925\n",
            "Epoch 374/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9570 - loss: 0.0891\n",
            "Epoch 375/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9505 - loss: 0.0982\n",
            "Epoch 376/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9531 - loss: 0.0937\n",
            "Epoch 377/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.0959\n",
            "Epoch 378/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9502 - loss: 0.1011\n",
            "Epoch 379/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9563 - loss: 0.0919\n",
            "Epoch 380/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9595 - loss: 0.0838\n",
            "Epoch 381/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9603 - loss: 0.0852\n",
            "Epoch 382/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9570 - loss: 0.0855\n",
            "Epoch 383/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9564 - loss: 0.0834\n",
            "Epoch 384/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9590 - loss: 0.0909\n",
            "Epoch 385/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9555 - loss: 0.0889\n",
            "Epoch 386/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9534 - loss: 0.0959\n",
            "Epoch 387/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9519 - loss: 0.0974\n",
            "Epoch 388/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9500 - loss: 0.0947\n",
            "Epoch 389/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.0843\n",
            "Epoch 390/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9585 - loss: 0.0799\n",
            "Epoch 391/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9514 - loss: 0.0964\n",
            "Epoch 392/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9593 - loss: 0.0890\n",
            "Epoch 393/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.0890\n",
            "Epoch 394/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9545 - loss: 0.0848\n",
            "Epoch 395/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9574 - loss: 0.0912\n",
            "Epoch 396/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.0940\n",
            "Epoch 397/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9484 - loss: 0.0958\n",
            "Epoch 398/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.0884\n",
            "Epoch 399/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.0914\n",
            "Epoch 400/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9563 - loss: 0.0968\n",
            "Epoch 401/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.0882\n",
            "Epoch 402/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9511 - loss: 0.0944\n",
            "Epoch 403/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.0946\n",
            "Epoch 404/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.0866\n",
            "Epoch 405/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9576 - loss: 0.0935\n",
            "Epoch 406/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.0929\n",
            "Epoch 407/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9523 - loss: 0.0878\n",
            "Epoch 408/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9584 - loss: 0.0875\n",
            "Epoch 409/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9594 - loss: 0.0862\n",
            "Epoch 410/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9595 - loss: 0.0890\n",
            "Epoch 411/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.0881\n",
            "Epoch 412/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.0890\n",
            "Epoch 413/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9506 - loss: 0.0984\n",
            "Epoch 414/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9529 - loss: 0.0864\n",
            "Epoch 415/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9575 - loss: 0.0838\n",
            "Epoch 416/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9546 - loss: 0.0944\n",
            "Epoch 417/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9547 - loss: 0.0846\n",
            "Epoch 418/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.0919\n",
            "Epoch 419/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0962\n",
            "Epoch 420/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9525 - loss: 0.0914\n",
            "Epoch 421/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9468 - loss: 0.0978\n",
            "Epoch 422/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9547 - loss: 0.0859\n",
            "Epoch 423/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9520 - loss: 0.0902\n",
            "Epoch 424/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.0893\n",
            "Epoch 425/425\n",
            "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9554 - loss: 0.0884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "jYtRewLWVDlk",
        "outputId": "b9e4d3eb-faeb-466c-de7c-5d318820d2a0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m550\u001b[0m)             │         \u001b[38;5;34m586,850\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)                 │         \u001b[38;5;34m801,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1067\u001b[0m)                │         \u001b[38;5;34m267,817\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">586,850</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">801,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1067</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">267,817</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,967,003\u001b[0m (18.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,967,003</span> (18.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,655,667\u001b[0m (6.32 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,655,667</span> (6.32 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,311,336\u001b[0m (12.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,311,336</span> (12.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label = 'accuracy',color='green')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "L-GeSY0TZenm",
        "outputId": "0c7b69b7-41ef-4c62-bd30-eeedd4e5f45d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],label='loss',color='red')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "F6SiYNiDaFJk",
        "outputId": "d6f00e10-f23a-4014-daea-cfbcaa638982"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Overfitting\"\n",
        "for i in range(30):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LGQLAo5ZH6-",
        "outputId": "5aa38cfc-cd9f-4040-92f3-61d52aced37e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "Overfitting occurs\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Overfitting occurs when\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Overfitting occurs when a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Overfitting occurs when a model\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Overfitting occurs when a model learns\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Overfitting occurs when a model learns the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Overfitting occurs when a model learns the training\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Overfitting occurs when a model learns the training data\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Overfitting occurs when a model learns the training data too\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Overfitting occurs when a model learns the training data too well\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Overfitting occurs when a model learns the training data too well including\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives the model\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives the model between\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives the model between data\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives the model between data and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives the model between data and identifying\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives the model between data and identifying spatial\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Overfitting occurs when a model learns the training data too well including noise and generalizes poorly to new data to new data arrives the model between data and identifying spatial hierarchies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"YOLO\"\n",
        "for i in range(15):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcaLSzSpoE_x",
        "outputId": "89c0e9e3-fad0-4034-f9ca-6f7b664eb826"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "YOLO you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "YOLO you only\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "YOLO you only look\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "YOLO you only look once\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "YOLO you only look once is\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "YOLO you only look once is a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "YOLO you only look once is a real\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "YOLO you only look once is a real time\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "YOLO you only look once is a real time object\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "YOLO you only look once is a real time object detection\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "YOLO you only look once is a real time object detection model\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "YOLO you only look once is a real time object detection model that\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "YOLO you only look once is a real time object detection model that predicts\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "YOLO you only look once is a real time object detection model that predicts bounding\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "YOLO you only look once is a real time object detection model that predicts bounding boxes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"AlexNet\"\n",
        "for i in range(20):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJBjBUKErkdT",
        "outputId": "f705a3c9-9180-412b-c354-15de4d565dfb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "AlexNet is\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "AlexNet is one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "AlexNet is one of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "AlexNet is one of the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "AlexNet is one of the first\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "AlexNet is one of the first cnn\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "AlexNet is one of the first cnn models\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "AlexNet is one of the first cnn models to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "AlexNet is one of the first cnn models to use\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "AlexNet is one of the first cnn models to use deep\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for image\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for image classification\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for image classification identifies\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for image classification identifies objects\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for image classification identifies objects and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for image classification identifies objects and identifying\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for image classification identifies objects and identifying data\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "AlexNet is one of the first cnn models to use deep architecture for image classification identifies objects and identifying data to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"LSTM\"\n",
        "for i in range(20):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zom0t1xWb6ym",
        "outputId": "3f5522f5-f014-4db5-e0f1-ee5ade6b9c3e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "LSTM long\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM long short\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "LSTM long short term\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM long short term memory\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM long short term memory improves\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM long short term memory improves rnns\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM long short term memory improves rnns by\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "LSTM long short term memory improves rnns by capturing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "LSTM long short term memory improves rnns by capturing long\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and mitigating\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and mitigating vanishing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and mitigating vanishing gradients\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and mitigating vanishing gradients vanishing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and mitigating vanishing gradients vanishing gradients\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and mitigating vanishing gradients vanishing gradients vanishing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and mitigating vanishing gradients vanishing gradients vanishing gradient\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "LSTM long short term memory improves rnns by capturing long term dependencies and mitigating vanishing gradients vanishing gradients vanishing gradient problem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"loss\"\n",
        "\n",
        "token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "pre = model.predict(pad_text)\n",
        "pos = np.argmax(pre)\n",
        "\n",
        "for word , index in tokenizer.word_index.items():\n",
        "  if(index==pos):\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPzhSm4aVzMq",
        "outputId": "78f00a1a-b26b-4381-b23a-035cbb77508e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "functions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"loss\"\n",
        "for i in range(5):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbLf0isAX4qR",
        "outputId": "f183d988-ff6a-4125-80af-36f84d0750ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "loss functions\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "loss functions like\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "loss functions like mean\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "loss functions like mean squared\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "loss functions like mean squared error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"relu\"\n",
        "for i in range(5):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=20 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxazaJJjYjNx",
        "outputId": "3c802caf-c056-48d2-af2c-9a0c81cf12aa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
            "relu in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "relu in ai\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "relu in ai models\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "relu in ai models can\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "relu in ai models can lead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"activation\"\n",
        "for i in range(20):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mluuTgSLYqhN",
        "outputId": "c12e1293-936f-41fa-c8c6-7e8c52f636c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "activation functions\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "activation functions like\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "activation functions like relu\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "activation functions like relu and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "activation functions like relu and sigmoid\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "activation functions like relu and sigmoid help\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "activation functions like relu and sigmoid help introduce\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "activation functions like relu and sigmoid help introduce non\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to solve\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to solve complex\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to solve complex problems\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to solve complex problems like\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to solve complex problems like image\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to solve complex problems like image recognition\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to solve complex problems like image recognition and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "activation functions like relu and sigmoid help introduce non linearity enabling networks to solve complex problems like image recognition and are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"deep\"\n",
        "for i in range(20):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5IuZ16qYtSx",
        "outputId": "99895644-a98c-4771-8f17-c0182be30ad4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "deep learning\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "deep learning models\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "deep learning models are\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "deep learning models are used\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "deep learning models are used in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "deep learning models are used in robotic\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "deep learning models are used in robotic vision\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "deep learning models are used in robotic vision enabling\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "deep learning models are used in robotic vision enabling robots\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "deep learning models are used in robotic vision enabling robots to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their surroundings\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their surroundings and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their surroundings and make\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their surroundings and make decisions\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their surroundings and make decisions in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their surroundings and make decisions in complex\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their surroundings and make decisions in complex environments\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "deep learning models are used in robotic vision enabling robots to interpret their surroundings and make decisions in complex environments autonomously\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"layers\"\n",
        "for i in range(5):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=23 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deJ8t5beY1Dv",
        "outputId": "6e370057-472f-4f08-dca6-de2d5d756294"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "layers for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "layers for video\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "layers for video classification\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "layers for video classification processes\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "layers for video classification processes video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"weight\"\n",
        "for i in range(15):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=100 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW2vJzNQY8WI",
        "outputId": "85a23ad4-3f12-410c-ab63-601799d7f789"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "weight initialization\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "weight initialization techniques\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "weight initialization techniques like\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "weight initialization techniques like xavier\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "weight initialization techniques like xavier or\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "weight initialization techniques like xavier or he\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "weight initialization techniques like xavier or he initialization\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "weight initialization techniques like xavier or he initialization help\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "weight initialization techniques like xavier or he initialization help start\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "weight initialization techniques like xavier or he initialization help start the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "weight initialization techniques like xavier or he initialization help start the training\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "weight initialization techniques like xavier or he initialization help start the training process\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "weight initialization techniques like xavier or he initialization help start the training process with\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "weight initialization techniques like xavier or he initialization help start the training process with balanced\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "weight initialization techniques like xavier or he initialization help start the training process with balanced weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ml\"\n",
        "for i in range(30):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=100 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAvD_mH3qTWU",
        "outputId": "e7d5ae5d-7e6b-49ec-c8f7-0ecf28d3a88a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "ml models\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "ml models can\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "ml models can be\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "ml models can be prone\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "ml models can be prone to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "ml models can be prone to adversarial\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "ml models can be prone to adversarial attacks\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "ml models can be prone to adversarial attacks where\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "ml models can be prone to adversarial attacks where small\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "ml models can be prone to adversarial attacks where small changes\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but poorly\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but poorly on\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but poorly on new\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but poorly on new data\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but poorly on new data arrives\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but poorly on new data arrives the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but poorly on new data arrives the training\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "ml models can be prone to adversarial attacks where small changes to input data mislead the model performs well on training data but poorly on new data arrives the training data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"large\"\n",
        "for i in range(20):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  pad_text = pad_sequences([token_text], maxlen=100 , padding='pre')\n",
        "\n",
        "  pre = model.predict(pad_text)\n",
        "  pos = np.argmax(pre)\n",
        "\n",
        "  for word , index in tokenizer.word_index.items():\n",
        "    if(index==pos):\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_mBbKGwwbhf",
        "outputId": "3f1eabb3-8cfd-41f8-e6ac-b6c06c2097fa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "large language\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "large language models\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "large language models like\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "large language models like gpt\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "large language models like gpt use\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "large language models like gpt use massive\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "large language models like gpt use massive datasets\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "large language models like gpt use massive datasets and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "large language models like gpt use massive datasets and deep\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "large language models like gpt use massive datasets and deep learning\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "large language models like gpt use massive datasets and deep learning to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate human\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate human like\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate human like text\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate human like text responses\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate human like text responses and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate human like text responses and text\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate human like text responses and text responses\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "large language models like gpt use massive datasets and deep learning to generate human like text responses and text responses to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('lstm_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0LTdrdW4z-7",
        "outputId": "af235589-6a61-483f-98f8-c823f389fdb0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-kh8ef15bdV"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}